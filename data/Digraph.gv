digraph {
	graph [size="147.6,147.6"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	139946075320136 [label="
 (2)" fillcolor=darkolivegreen1]
	139946075457408 [label=SliceBackward0]
	139946075457184 -> 139946075457408
	139946075457184 [label=SelectBackward0]
	139946075457688 -> 139946075457184
	139946075457688 [label=AddmmBackward0]
	139946075457520 -> 139946075457688
	139946075410744 [label="model.last_linear.1.bias
 (2)" fillcolor=lightblue]
	139946075410744 -> 139946075457520
	139946075457520 [label=AccumulateGrad]
	139946075457744 -> 139946075457688
	139946075457744 [label=MulBackward0]
	139946075457912 -> 139946075457744
	139946075457912 [label=ViewBackward0]
	139946075458024 -> 139946075457912
	139946075458024 [label=MeanBackward1]
	139946075458136 -> 139946075458024
	139946075458136 [label=ReluBackward0]
	139946075458248 -> 139946075458136
	139946075458248 [label=NativeBatchNormBackward0]
	139946075458360 -> 139946075458248
	139946075458360 [label=MkldnnConvolutionBackward0]
	139946075458584 -> 139946075458360
	139946075458584 [label=MkldnnConvolutionBackward0]
	139946075458752 -> 139946075458584
	139946075458752 [label=ReluBackward0]
	139946075458920 -> 139946075458752
	139946075458920 [label=NativeBatchNormBackward0]
	139946075459032 -> 139946075458920
	139946075459032 [label=MkldnnConvolutionBackward0]
	139946075459256 -> 139946075459032
	139946075459256 [label=MkldnnConvolutionBackward0]
	139946075459424 -> 139946075459256
	139946075459424 [label=AddBackward0]
	139945955033160 -> 139946075459424
	139945955033160 [label=MaxPool2DWithIndicesBackward0]
	139945955033328 -> 139945955033160
	139945955033328 [label=NativeBatchNormBackward0]
	139945955033440 -> 139945955033328
	139945955033440 [label=MkldnnConvolutionBackward0]
	139945955033664 -> 139945955033440
	139945955033664 [label=MkldnnConvolutionBackward0]
	139945955033832 -> 139945955033664
	139945955033832 [label=ReluBackward0]
	139945955034000 -> 139945955033832
	139945955034000 [label=NativeBatchNormBackward0]
	139945955034112 -> 139945955034000
	139945955034112 [label=MkldnnConvolutionBackward0]
	139945955034336 -> 139945955034112
	139945955034336 [label=MkldnnConvolutionBackward0]
	139945955034504 -> 139945955034336
	139945955034504 [label=ReluBackward0]
	139945955034672 -> 139945955034504
	139945955034672 [label=AddBackward0]
	139945955034784 -> 139945955034672
	139945955034784 [label=NativeBatchNormBackward0]
	139945955034952 -> 139945955034784
	139945955034952 [label=MkldnnConvolutionBackward0]
	139945955035176 -> 139945955034952
	139945955035176 [label=MkldnnConvolutionBackward0]
	139945955035344 -> 139945955035176
	139945955035344 [label=ReluBackward0]
	139945955035512 -> 139945955035344
	139945955035512 [label=NativeBatchNormBackward0]
	139945955035680 -> 139945955035512
	139945955035680 [label=MkldnnConvolutionBackward0]
	139945955035904 -> 139945955035680
	139945955035904 [label=MkldnnConvolutionBackward0]
	139945955036072 -> 139945955035904
	139945955036072 [label=ReluBackward0]
	139945955036240 -> 139945955036072
	139945955036240 [label=NativeBatchNormBackward0]
	139945955036408 -> 139945955036240
	139945955036408 [label=MkldnnConvolutionBackward0]
	139945955036632 -> 139945955036408
	139945955036632 [label=MkldnnConvolutionBackward0]
	139945955036800 -> 139945955036632
	139945955036800 [label=ReluBackward0]
	139945955034840 -> 139945955036800
	139945955034840 [label=AddBackward0]
	139945955037080 -> 139945955034840
	139945955037080 [label=NativeBatchNormBackward0]
	139945955041408 -> 139945955037080
	139945955041408 [label=MkldnnConvolutionBackward0]
	139945955041632 -> 139945955041408
	139945955041632 [label=MkldnnConvolutionBackward0]
	139945955041800 -> 139945955041632
	139945955041800 [label=ReluBackward0]
	139945955041968 -> 139945955041800
	139945955041968 [label=NativeBatchNormBackward0]
	139945955042136 -> 139945955041968
	139945955042136 [label=MkldnnConvolutionBackward0]
	139945955042360 -> 139945955042136
	139945955042360 [label=MkldnnConvolutionBackward0]
	139945955042528 -> 139945955042360
	139945955042528 [label=ReluBackward0]
	139945955042696 -> 139945955042528
	139945955042696 [label=NativeBatchNormBackward0]
	139945955042864 -> 139945955042696
	139945955042864 [label=MkldnnConvolutionBackward0]
	139945955043088 -> 139945955042864
	139945955043088 [label=MkldnnConvolutionBackward0]
	139945955043256 -> 139945955043088
	139945955043256 [label=ReluBackward0]
	139945955037136 -> 139945955043256
	139945955037136 [label=AddBackward0]
	139945955043536 -> 139945955037136
	139945955043536 [label=NativeBatchNormBackward0]
	139945955043704 -> 139945955043536
	139945955043704 [label=MkldnnConvolutionBackward0]
	139945955043928 -> 139945955043704
	139945955043928 [label=MkldnnConvolutionBackward0]
	139945955044096 -> 139945955043928
	139945955044096 [label=ReluBackward0]
	139945955044264 -> 139945955044096
	139945955044264 [label=NativeBatchNormBackward0]
	139945955044432 -> 139945955044264
	139945955044432 [label=MkldnnConvolutionBackward0]
	139945955044656 -> 139945955044432
	139945955044656 [label=MkldnnConvolutionBackward0]
	139945955044824 -> 139945955044656
	139945955044824 [label=ReluBackward0]
	139945955044992 -> 139945955044824
	139945955044992 [label=NativeBatchNormBackward0]
	139945955045160 -> 139945955044992
	139945955045160 [label=MkldnnConvolutionBackward0]
	139945955053640 -> 139945955045160
	139945955053640 [label=MkldnnConvolutionBackward0]
	139945955053808 -> 139945955053640
	139945955053808 [label=ReluBackward0]
	139945955043592 -> 139945955053808
	139945955043592 [label=AddBackward0]
	139945955054088 -> 139945955043592
	139945955054088 [label=NativeBatchNormBackward0]
	139945955054256 -> 139945955054088
	139945955054256 [label=MkldnnConvolutionBackward0]
	139945955054480 -> 139945955054256
	139945955054480 [label=MkldnnConvolutionBackward0]
	139945955054648 -> 139945955054480
	139945955054648 [label=ReluBackward0]
	139945955054816 -> 139945955054648
	139945955054816 [label=NativeBatchNormBackward0]
	139945955054984 -> 139945955054816
	139945955054984 [label=MkldnnConvolutionBackward0]
	139945955055208 -> 139945955054984
	139945955055208 [label=MkldnnConvolutionBackward0]
	139945955055376 -> 139945955055208
	139945955055376 [label=ReluBackward0]
	139945955055544 -> 139945955055376
	139945955055544 [label=NativeBatchNormBackward0]
	139945955055712 -> 139945955055544
	139945955055712 [label=MkldnnConvolutionBackward0]
	139945955055936 -> 139945955055712
	139945955055936 [label=MkldnnConvolutionBackward0]
	139945955056104 -> 139945955055936
	139945955056104 [label=ReluBackward0]
	139945955054144 -> 139945955056104
	139945955054144 [label=AddBackward0]
	139945955056384 -> 139945955054144
	139945955056384 [label=NativeBatchNormBackward0]
	139945955056552 -> 139945955056384
	139945955056552 [label=MkldnnConvolutionBackward0]
	139945955056776 -> 139945955056552
	139945955056776 [label=MkldnnConvolutionBackward0]
	139945955056944 -> 139945955056776
	139945955056944 [label=ReluBackward0]
	139945955057112 -> 139945955056944
	139945955057112 [label=NativeBatchNormBackward0]
	139945955057280 -> 139945955057112
	139945955057280 [label=MkldnnConvolutionBackward0]
	139945955057504 -> 139945955057280
	139945955057504 [label=MkldnnConvolutionBackward0]
	139945955065928 -> 139945955057504
	139945955065928 [label=ReluBackward0]
	139945955066096 -> 139945955065928
	139945955066096 [label=NativeBatchNormBackward0]
	139945955066264 -> 139945955066096
	139945955066264 [label=MkldnnConvolutionBackward0]
	139945955066488 -> 139945955066264
	139945955066488 [label=MkldnnConvolutionBackward0]
	139945955066656 -> 139945955066488
	139945955066656 [label=ReluBackward0]
	139945955056440 -> 139945955066656
	139945955056440 [label=AddBackward0]
	139945955066936 -> 139945955056440
	139945955066936 [label=NativeBatchNormBackward0]
	139945955067104 -> 139945955066936
	139945955067104 [label=MkldnnConvolutionBackward0]
	139945955067328 -> 139945955067104
	139945955067328 [label=MkldnnConvolutionBackward0]
	139945955067496 -> 139945955067328
	139945955067496 [label=ReluBackward0]
	139945955067664 -> 139945955067496
	139945955067664 [label=NativeBatchNormBackward0]
	139945955067832 -> 139945955067664
	139945955067832 [label=MkldnnConvolutionBackward0]
	139945955068056 -> 139945955067832
	139945955068056 [label=MkldnnConvolutionBackward0]
	139945955068224 -> 139945955068056
	139945955068224 [label=ReluBackward0]
	139945955068392 -> 139945955068224
	139945955068392 [label=NativeBatchNormBackward0]
	139945955068560 -> 139945955068392
	139945955068560 [label=MkldnnConvolutionBackward0]
	139945955068784 -> 139945955068560
	139945955068784 [label=MkldnnConvolutionBackward0]
	139945955068952 -> 139945955068784
	139945955068952 [label=ReluBackward0]
	139945955066992 -> 139945955068952
	139945955066992 [label=AddBackward0]
	139945955069232 -> 139945955066992
	139945955069232 [label=NativeBatchNormBackward0]
	139945955069400 -> 139945955069232
	139945955069400 [label=MkldnnConvolutionBackward0]
	139945955069624 -> 139945955069400
	139945955069624 [label=MkldnnConvolutionBackward0]
	139945955069792 -> 139945955069624
	139945955069792 [label=ReluBackward0]
	139945955078216 -> 139945955069792
	139945955078216 [label=NativeBatchNormBackward0]
	139945955078384 -> 139945955078216
	139945955078384 [label=MkldnnConvolutionBackward0]
	139945955078608 -> 139945955078384
	139945955078608 [label=MkldnnConvolutionBackward0]
	139945955078776 -> 139945955078608
	139945955078776 [label=ReluBackward0]
	139945955078944 -> 139945955078776
	139945955078944 [label=NativeBatchNormBackward0]
	139945955079112 -> 139945955078944
	139945955079112 [label=MkldnnConvolutionBackward0]
	139945955079336 -> 139945955079112
	139945955079336 [label=MkldnnConvolutionBackward0]
	139945955079504 -> 139945955079336
	139945955079504 [label=ReluBackward0]
	139945955069288 -> 139945955079504
	139945955069288 [label=AddBackward0]
	139945955079784 -> 139945955069288
	139945955079784 [label=NativeBatchNormBackward0]
	139945955079952 -> 139945955079784
	139945955079952 [label=MkldnnConvolutionBackward0]
	139945955080176 -> 139945955079952
	139945955080176 [label=MkldnnConvolutionBackward0]
	139945955080344 -> 139945955080176
	139945955080344 [label=ReluBackward0]
	139945955080512 -> 139945955080344
	139945955080512 [label=NativeBatchNormBackward0]
	139945955080680 -> 139945955080512
	139945955080680 [label=MkldnnConvolutionBackward0]
	139945955080904 -> 139945955080680
	139945955080904 [label=MkldnnConvolutionBackward0]
	139945955081072 -> 139945955080904
	139945955081072 [label=ReluBackward0]
	139945955081240 -> 139945955081072
	139945955081240 [label=NativeBatchNormBackward0]
	139945955081408 -> 139945955081240
	139945955081408 [label=MkldnnConvolutionBackward0]
	139945955081632 -> 139945955081408
	139945955081632 [label=MkldnnConvolutionBackward0]
	139945955081800 -> 139945955081632
	139945955081800 [label=ReluBackward0]
	139945955079840 -> 139945955081800
	139945955079840 [label=AddBackward0]
	139945955082080 -> 139945955079840
	139945955082080 [label=MaxPool2DWithIndicesBackward0]
	139945955094600 -> 139945955082080
	139945955094600 [label=NativeBatchNormBackward0]
	139945955094768 -> 139945955094600
	139945955094768 [label=MkldnnConvolutionBackward0]
	139945955094992 -> 139945955094768
	139945955094992 [label=MkldnnConvolutionBackward0]
	139945955095160 -> 139945955094992
	139945955095160 [label=ReluBackward0]
	139945955095328 -> 139945955095160
	139945955095328 [label=NativeBatchNormBackward0]
	139945955095496 -> 139945955095328
	139945955095496 [label=MkldnnConvolutionBackward0]
	139945955095720 -> 139945955095496
	139945955095720 [label=MkldnnConvolutionBackward0]
	139945955095888 -> 139945955095720
	139945955095888 [label=ReluBackward0]
	139945955096056 -> 139945955095888
	139945955096056 [label=AddBackward0]
	139945955096224 -> 139945955096056
	139945955096224 [label=MaxPool2DWithIndicesBackward0]
	139945955096392 -> 139945955096224
	139945955096392 [label=NativeBatchNormBackward0]
	139945955096560 -> 139945955096392
	139945955096560 [label=MkldnnConvolutionBackward0]
	139945955096784 -> 139945955096560
	139945955096784 [label=MkldnnConvolutionBackward0]
	139945955096952 -> 139945955096784
	139945955096952 [label=ReluBackward0]
	139945955097120 -> 139945955096952
	139945955097120 [label=NativeBatchNormBackward0]
	139945955097288 -> 139945955097120
	139945955097288 [label=MkldnnConvolutionBackward0]
	139945955097512 -> 139945955097288
	139945955097512 [label=MkldnnConvolutionBackward0]
	139945955097680 -> 139945955097512
	139945955097680 [label=ReluBackward0]
	139945955097848 -> 139945955097680
	139945955097848 [label=AddBackward0]
	139945955098016 -> 139945955097848
	139945955098016 [label=MaxPool2DWithIndicesBackward0]
	139945955098184 -> 139945955098016
	139945955098184 [label=NativeBatchNormBackward0]
	139945955098352 -> 139945955098184
	139945955098352 [label=MkldnnConvolutionBackward0]
	139945955098576 -> 139945955098352
	139945955098576 [label=MkldnnConvolutionBackward0]
	139945955111096 -> 139945955098576
	139945955111096 [label=ReluBackward0]
	139945955111264 -> 139945955111096
	139945955111264 [label=NativeBatchNormBackward0]
	139945955111432 -> 139945955111264
	139945955111432 [label=MkldnnConvolutionBackward0]
	139945955111656 -> 139945955111432
	139945955111656 [label=MkldnnConvolutionBackward0]
	139945955111824 -> 139945955111656
	139945955111824 [label=ReluBackward0]
	139945955111992 -> 139945955111824
	139945955111992 [label=NativeBatchNormBackward0]
	139945955112160 -> 139945955111992
	139945955112160 [label=MkldnnConvolutionBackward0]
	139945955112384 -> 139945955112160
	139945955112384 [label=ReluBackward0]
	139945955112552 -> 139945955112384
	139945955112552 [label=NativeBatchNormBackward0]
	139945955112720 -> 139945955112552
	139945955112720 [label=MkldnnConvolutionBackward0]
	139945955112944 -> 139945955112720
	139946113937480 [label="model.conv1.weight
 (32, 3, 3, 3)" fillcolor=lightblue]
	139946113937480 -> 139945955112944
	139945955112944 [label=AccumulateGrad]
	139945955112776 -> 139945955112552
	139946113937560 [label="model.bn1.weight
 (32)" fillcolor=lightblue]
	139946113937560 -> 139945955112776
	139945955112776 [label=AccumulateGrad]
	139945955112832 -> 139945955112552
	139946113937640 [label="model.bn1.bias
 (32)" fillcolor=lightblue]
	139946113937640 -> 139945955112832
	139945955112832 [label=AccumulateGrad]
	139945955112440 -> 139945955112160
	139946113938040 [label="model.conv2.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	139946113938040 -> 139945955112440
	139945955112440 [label=AccumulateGrad]
	139945955112216 -> 139945955111992
	139946113938120 [label="model.bn2.weight
 (64)" fillcolor=lightblue]
	139946113938120 -> 139945955112216
	139945955112216 [label=AccumulateGrad]
	139945955112272 -> 139945955111992
	139946113938200 [label="model.bn2.bias
 (64)" fillcolor=lightblue]
	139946113938200 -> 139945955112272
	139945955112272 [label=AccumulateGrad]
	139945955111880 -> 139945955111656
	139946113939400 [label="model.block1.rep.0.conv1.weight
 (64, 1, 3, 3)" fillcolor=lightblue]
	139946113939400 -> 139945955111880
	139945955111880 [label=AccumulateGrad]
	139945955111712 -> 139945955111432
	139946113939560 [label="model.block1.rep.0.pointwise.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	139946113939560 -> 139945955111712
	139945955111712 [label=AccumulateGrad]
	139945955111488 -> 139945955111264
	139946113939640 [label="model.block1.rep.1.weight
 (128)" fillcolor=lightblue]
	139946113939640 -> 139945955111488
	139945955111488 [label=AccumulateGrad]
	139945955111544 -> 139945955111264
	139946113939720 [label="model.block1.rep.1.bias
 (128)" fillcolor=lightblue]
	139946113939720 -> 139945955111544
	139945955111544 [label=AccumulateGrad]
	139945955111152 -> 139945955098576
	139946113940120 [label="model.block1.rep.3.conv1.weight
 (128, 1, 3, 3)" fillcolor=lightblue]
	139946113940120 -> 139945955111152
	139945955111152 [label=AccumulateGrad]
	139945955110984 -> 139945955098352
	139946113940280 [label="model.block1.rep.3.pointwise.weight
 (128, 128, 1, 1)" fillcolor=lightblue]
	139946113940280 -> 139945955110984
	139945955110984 [label=AccumulateGrad]
	139945955098408 -> 139945955098184
	139946113940360 [label="model.block1.rep.4.weight
 (128)" fillcolor=lightblue]
	139946113940360 -> 139945955098408
	139945955098408 [label=AccumulateGrad]
	139945955098464 -> 139945955098184
	139946113940440 [label="model.block1.rep.4.bias
 (128)" fillcolor=lightblue]
	139946113940440 -> 139945955098464
	139945955098464 [label=AccumulateGrad]
	139945955098072 -> 139945955097848
	139945955098072 [label=NativeBatchNormBackward0]
	139945955098240 -> 139945955098072
	139945955098240 [label=MkldnnConvolutionBackward0]
	139945955111824 -> 139945955098240
	139945955111320 -> 139945955098240
	139946113938840 [label="model.block1.skip.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	139946113938840 -> 139945955111320
	139945955111320 [label=AccumulateGrad]
	139945955098520 -> 139945955098072
	139946113938920 [label="model.block1.skipbn.weight
 (128)" fillcolor=lightblue]
	139946113938920 -> 139945955098520
	139945955098520 [label=AccumulateGrad]
	139945955111040 -> 139945955098072
	139946113939000 [label="model.block1.skipbn.bias
 (128)" fillcolor=lightblue]
	139946113939000 -> 139945955111040
	139945955111040 [label=AccumulateGrad]
	139945955097736 -> 139945955097512
	139946113941400 [label="model.block2.rep.1.conv1.weight
 (128, 1, 3, 3)" fillcolor=lightblue]
	139946113941400 -> 139945955097736
	139945955097736 [label=AccumulateGrad]
	139945955097568 -> 139945955097288
	139946114039960 [label="model.block2.rep.1.pointwise.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	139946114039960 -> 139945955097568
	139945955097568 [label=AccumulateGrad]
	139945955097344 -> 139945955097120
	139946114040040 [label="model.block2.rep.2.weight
 (256)" fillcolor=lightblue]
	139946114040040 -> 139945955097344
	139945955097344 [label=AccumulateGrad]
	139945955097400 -> 139945955097120
	139946114040120 [label="model.block2.rep.2.bias
 (256)" fillcolor=lightblue]
	139946114040120 -> 139945955097400
	139945955097400 [label=AccumulateGrad]
	139945955097008 -> 139945955096784
	139946114040520 [label="model.block2.rep.4.conv1.weight
 (256, 1, 3, 3)" fillcolor=lightblue]
	139946114040520 -> 139945955097008
	139945955097008 [label=AccumulateGrad]
	139945955096840 -> 139945955096560
	139946114040680 [label="model.block2.rep.4.pointwise.weight
 (256, 256, 1, 1)" fillcolor=lightblue]
	139946114040680 -> 139945955096840
	139945955096840 [label=AccumulateGrad]
	139945955096616 -> 139945955096392
	139946114040760 [label="model.block2.rep.5.weight
 (256)" fillcolor=lightblue]
	139946114040760 -> 139945955096616
	139945955096616 [label=AccumulateGrad]
	139945955096672 -> 139945955096392
	139946114040840 [label="model.block2.rep.5.bias
 (256)" fillcolor=lightblue]
	139946114040840 -> 139945955096672
	139945955096672 [label=AccumulateGrad]
	139945955096280 -> 139945955096056
	139945955096280 [label=NativeBatchNormBackward0]
	139945955096448 -> 139945955096280
	139945955096448 [label=MkldnnConvolutionBackward0]
	139945955097848 -> 139945955096448
	139945955097176 -> 139945955096448
	139946113940840 [label="model.block2.skip.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	139946113940840 -> 139945955097176
	139945955097176 [label=AccumulateGrad]
	139945955096728 -> 139945955096280
	139946113940920 [label="model.block2.skipbn.weight
 (256)" fillcolor=lightblue]
	139946113940920 -> 139945955096728
	139945955096728 [label=AccumulateGrad]
	139945955096896 -> 139945955096280
	139946113941000 [label="model.block2.skipbn.bias
 (256)" fillcolor=lightblue]
	139946113941000 -> 139945955096896
	139945955096896 [label=AccumulateGrad]
	139945955095944 -> 139945955095720
	139946114041800 [label="model.block3.rep.1.conv1.weight
 (256, 1, 3, 3)" fillcolor=lightblue]
	139946114041800 -> 139945955095944
	139945955095944 [label=AccumulateGrad]
	139945955095776 -> 139945955095496
	139946114041960 [label="model.block3.rep.1.pointwise.weight
 (728, 256, 1, 1)" fillcolor=lightblue]
	139946114041960 -> 139945955095776
	139945955095776 [label=AccumulateGrad]
	139945955095552 -> 139945955095328
	139946114042040 [label="model.block3.rep.2.weight
 (728)" fillcolor=lightblue]
	139946114042040 -> 139945955095552
	139945955095552 [label=AccumulateGrad]
	139945955095608 -> 139945955095328
	139946114042120 [label="model.block3.rep.2.bias
 (728)" fillcolor=lightblue]
	139946114042120 -> 139945955095608
	139945955095608 [label=AccumulateGrad]
	139945955095216 -> 139945955094992
	139946114042520 [label="model.block3.rep.4.conv1.weight
 (728, 1, 3, 3)" fillcolor=lightblue]
	139946114042520 -> 139945955095216
	139945955095216 [label=AccumulateGrad]
	139945955095048 -> 139945955094768
	139946114042680 [label="model.block3.rep.4.pointwise.weight
 (728, 728, 1, 1)" fillcolor=lightblue]
	139946114042680 -> 139945955095048
	139945955095048 [label=AccumulateGrad]
	139945955094824 -> 139945955094600
	139946114042760 [label="model.block3.rep.5.weight
 (728)" fillcolor=lightblue]
	139946114042760 -> 139945955094824
	139945955094824 [label=AccumulateGrad]
	139945955094880 -> 139945955094600
	139946114042840 [label="model.block3.rep.5.bias
 (728)" fillcolor=lightblue]
	139946114042840 -> 139945955094880
	139945955094880 [label=AccumulateGrad]
	139945955082136 -> 139945955079840
	139945955082136 [label=NativeBatchNormBackward0]
	139945955094656 -> 139945955082136
	139945955094656 [label=MkldnnConvolutionBackward0]
	139945955096056 -> 139945955094656
	139945955095384 -> 139945955094656
	139946114041240 [label="model.block3.skip.weight
 (728, 256, 1, 1)" fillcolor=lightblue]
	139946114041240 -> 139945955095384
	139945955095384 [label=AccumulateGrad]
	139945955094936 -> 139945955082136
	139946114041320 [label="model.block3.skipbn.weight
 (728)" fillcolor=lightblue]
	139946114041320 -> 139945955094936
	139945955094936 [label=AccumulateGrad]
	139945955095104 -> 139945955082136
	139946114041400 [label="model.block3.skipbn.bias
 (728)" fillcolor=lightblue]
	139946114041400 -> 139945955095104
	139945955095104 [label=AccumulateGrad]
	139945955081856 -> 139945955081632
	139946114043240 [label="model.block4.rep.1.conv1.weight
 (728, 1, 3, 3)" fillcolor=lightblue]
	139946114043240 -> 139945955081856
	139945955081856 [label=AccumulateGrad]
	139945955081688 -> 139945955081408
	139946114043400 [label="model.block4.rep.1.pointwise.weight
 (728, 728, 1, 1)" fillcolor=lightblue]
	139946114043400 -> 139945955081688
	139945955081688 [label=AccumulateGrad]
	139945955081464 -> 139945955081240
	139946114043480 [label="model.block4.rep.2.weight
 (728)" fillcolor=lightblue]
	139946114043480 -> 139945955081464
	139945955081464 [label=AccumulateGrad]
	139945955081520 -> 139945955081240
	139946114043560 [label="model.block4.rep.2.bias
 (728)" fillcolor=lightblue]
	139946114043560 -> 139945955081520
	139945955081520 [label=AccumulateGrad]
	139945955081128 -> 139945955080904
	139946114134168 [label="model.block4.rep.4.conv1.weight
 (728, 1, 3, 3)" fillcolor=lightblue]
	139946114134168 -> 139945955081128
	139945955081128 [label=AccumulateGrad]
	139945955080960 -> 139945955080680
	139946114134328 [label="model.block4.rep.4.pointwise.weight
 (728, 728, 1, 1)" fillcolor=lightblue]
	139946114134328 -> 139945955080960
	139945955080960 [label=AccumulateGrad]
	139945955080736 -> 139945955080512
	139946114134408 [label="model.block4.rep.5.weight
 (728)" fillcolor=lightblue]
	139946114134408 -> 139945955080736
	139945955080736 [label=AccumulateGrad]
	139945955080792 -> 139945955080512
	139946114134488 [label="model.block4.rep.5.bias
 (728)" fillcolor=lightblue]
	139946114134488 -> 139945955080792
	139945955080792 [label=AccumulateGrad]
	139945955080400 -> 139945955080176
	139946114134888 [label="model.block4.rep.7.conv1.weight
 (728, 1, 3, 3)" fillcolor=lightblue]
	139946114134888 -> 139945955080400
	139945955080400 [label=AccumulateGrad]
	139945955080232 -> 139945955079952
	139946114135048 [label="model.block4.rep.7.pointwise.weight
 (728, 728, 1, 1)" fillcolor=lightblue]
	139946114135048 -> 139945955080232
	139945955080232 [label=AccumulateGrad]
	139945955080008 -> 139945955079784
	139946114135128 [label="model.block4.rep.8.weight
 (728)" fillcolor=lightblue]
	139946114135128 -> 139945955080008
	139945955080008 [label=AccumulateGrad]
	139945955080064 -> 139945955079784
	139946114135208 [label="model.block4.rep.8.bias
 (728)" fillcolor=lightblue]
	139946114135208 -> 139945955080064
	139945955080064 [label=AccumulateGrad]
	139945955079840 -> 139945955069288
	139945955079560 -> 139945955079336
	139946114135608 [label="model.block5.rep.1.conv1.weight
 (728, 1, 3, 3)" fillcolor=lightblue]
	139946114135608 -> 139945955079560
	139945955079560 [label=AccumulateGrad]
	139945955079392 -> 139945955079112
	139946114135768 [label="model.block5.rep.1.pointwise.weight
 (728, 728, 1, 1)" fillcolor=lightblue]
	139946114135768 -> 139945955079392
	139945955079392 [label=AccumulateGrad]
	139945955079168 -> 139945955078944
	139946114135848 [label="model.block5.rep.2.weight
 (728)" fillcolor=lightblue]
	139946114135848 -> 139945955079168
	139945955079168 [label=AccumulateGrad]
	139945955079224 -> 139945955078944
	139946114135928 [label="model.block5.rep.2.bias
 (728)" fillcolor=lightblue]
	139946114135928 -> 139945955079224
	139945955079224 [label=AccumulateGrad]
	139945955078832 -> 139945955078608
	139946114136328 [label="model.block5.rep.4.conv1.weight
 (728, 1, 3, 3)" fillcolor=lightblue]
	139946114136328 -> 139945955078832
	139945955078832 [label=AccumulateGrad]
	139945955078664 -> 139945955078384
	139946114136488 [label="model.block5.rep.4.pointwise.weight
 (728, 728, 1, 1)" fillcolor=lightblue]
	139946114136488 -> 139945955078664
	139945955078664 [label=AccumulateGrad]
	139945955078440 -> 139945955078216
	139946114136568 [label="model.block5.rep.5.weight
 (728)" fillcolor=lightblue]
	139946114136568 -> 139945955078440
	139945955078440 [label=AccumulateGrad]
	139945955078496 -> 139945955078216
	139946114136648 [label="model.block5.rep.5.bias
 (728)" fillcolor=lightblue]
	139946114136648 -> 139945955078496
	139945955078496 [label=AccumulateGrad]
	139945955069848 -> 139945955069624
	139946114137048 [label="model.block5.rep.7.conv1.weight
 (728, 1, 3, 3)" fillcolor=lightblue]
	139946114137048 -> 139945955069848
	139945955069848 [label=AccumulateGrad]
	139945955069680 -> 139945955069400
	139946114137208 [label="model.block5.rep.7.pointwise.weight
 (728, 728, 1, 1)" fillcolor=lightblue]
	139946114137208 -> 139945955069680
	139945955069680 [label=AccumulateGrad]
	139945955069456 -> 139945955069232
	139946114137288 [label="model.block5.rep.8.weight
 (728)" fillcolor=lightblue]
	139946114137288 -> 139945955069456
	139945955069456 [label=AccumulateGrad]
	139945955069512 -> 139945955069232
	139946114137368 [label="model.block5.rep.8.bias
 (728)" fillcolor=lightblue]
	139946114137368 -> 139945955069512
	139945955069512 [label=AccumulateGrad]
	139945955069288 -> 139945955066992
	139945955069008 -> 139945955068784
	139946114137768 [label="model.block6.rep.1.conv1.weight
 (728, 1, 3, 3)" fillcolor=lightblue]
	139946114137768 -> 139945955069008
	139945955069008 [label=AccumulateGrad]
	139945955068840 -> 139945955068560
	139946114137928 [label="model.block6.rep.1.pointwise.weight
 (728, 728, 1, 1)" fillcolor=lightblue]
	139946114137928 -> 139945955068840
	139945955068840 [label=AccumulateGrad]
	139945955068616 -> 139945955068392
	139946114138008 [label="model.block6.rep.2.weight
 (728)" fillcolor=lightblue]
	139946114138008 -> 139945955068616
	139945955068616 [label=AccumulateGrad]
	139945955068672 -> 139945955068392
	139946103107656 [label="model.block6.rep.2.bias
 (728)" fillcolor=lightblue]
	139946103107656 -> 139945955068672
	139945955068672 [label=AccumulateGrad]
	139945955068280 -> 139945955068056
	139946103108056 [label="model.block6.rep.4.conv1.weight
 (728, 1, 3, 3)" fillcolor=lightblue]
	139946103108056 -> 139945955068280
	139945955068280 [label=AccumulateGrad]
	139945955068112 -> 139945955067832
	139946103108216 [label="model.block6.rep.4.pointwise.weight
 (728, 728, 1, 1)" fillcolor=lightblue]
	139946103108216 -> 139945955068112
	139945955068112 [label=AccumulateGrad]
	139945955067888 -> 139945955067664
	139946103108296 [label="model.block6.rep.5.weight
 (728)" fillcolor=lightblue]
	139946103108296 -> 139945955067888
	139945955067888 [label=AccumulateGrad]
	139945955067944 -> 139945955067664
	139946103108376 [label="model.block6.rep.5.bias
 (728)" fillcolor=lightblue]
	139946103108376 -> 139945955067944
	139945955067944 [label=AccumulateGrad]
	139945955067552 -> 139945955067328
	139946103108776 [label="model.block6.rep.7.conv1.weight
 (728, 1, 3, 3)" fillcolor=lightblue]
	139946103108776 -> 139945955067552
	139945955067552 [label=AccumulateGrad]
	139945955067384 -> 139945955067104
	139946103108936 [label="model.block6.rep.7.pointwise.weight
 (728, 728, 1, 1)" fillcolor=lightblue]
	139946103108936 -> 139945955067384
	139945955067384 [label=AccumulateGrad]
	139945955067160 -> 139945955066936
	139946103109016 [label="model.block6.rep.8.weight
 (728)" fillcolor=lightblue]
	139946103109016 -> 139945955067160
	139945955067160 [label=AccumulateGrad]
	139945955067216 -> 139945955066936
	139946103109096 [label="model.block6.rep.8.bias
 (728)" fillcolor=lightblue]
	139946103109096 -> 139945955067216
	139945955067216 [label=AccumulateGrad]
	139945955066992 -> 139945955056440
	139945955066712 -> 139945955066488
	139946103109496 [label="model.block7.rep.1.conv1.weight
 (728, 1, 3, 3)" fillcolor=lightblue]
	139946103109496 -> 139945955066712
	139945955066712 [label=AccumulateGrad]
	139945955066544 -> 139945955066264
	139946103109656 [label="model.block7.rep.1.pointwise.weight
 (728, 728, 1, 1)" fillcolor=lightblue]
	139946103109656 -> 139945955066544
	139945955066544 [label=AccumulateGrad]
	139945955066320 -> 139945955066096
	139946103109736 [label="model.block7.rep.2.weight
 (728)" fillcolor=lightblue]
	139946103109736 -> 139945955066320
	139945955066320 [label=AccumulateGrad]
	139945955066376 -> 139945955066096
	139946103109816 [label="model.block7.rep.2.bias
 (728)" fillcolor=lightblue]
	139946103109816 -> 139945955066376
	139945955066376 [label=AccumulateGrad]
	139945955065984 -> 139945955057504
	139946103110216 [label="model.block7.rep.4.conv1.weight
 (728, 1, 3, 3)" fillcolor=lightblue]
	139946103110216 -> 139945955065984
	139945955065984 [label=AccumulateGrad]
	139945955057560 -> 139945955057280
	139946103110376 [label="model.block7.rep.4.pointwise.weight
 (728, 728, 1, 1)" fillcolor=lightblue]
	139946103110376 -> 139945955057560
	139945955057560 [label=AccumulateGrad]
	139945955057336 -> 139945955057112
	139946103110456 [label="model.block7.rep.5.weight
 (728)" fillcolor=lightblue]
	139946103110456 -> 139945955057336
	139945955057336 [label=AccumulateGrad]
	139945955057392 -> 139945955057112
	139946103110536 [label="model.block7.rep.5.bias
 (728)" fillcolor=lightblue]
	139946103110536 -> 139945955057392
	139945955057392 [label=AccumulateGrad]
	139945955057000 -> 139945955056776
	139946103110936 [label="model.block7.rep.7.conv1.weight
 (728, 1, 3, 3)" fillcolor=lightblue]
	139946103110936 -> 139945955057000
	139945955057000 [label=AccumulateGrad]
	139945955056832 -> 139945955056552
	139946103111096 [label="model.block7.rep.7.pointwise.weight
 (728, 728, 1, 1)" fillcolor=lightblue]
	139946103111096 -> 139945955056832
	139945955056832 [label=AccumulateGrad]
	139945955056608 -> 139945955056384
	139946103111176 [label="model.block7.rep.8.weight
 (728)" fillcolor=lightblue]
	139946103111176 -> 139945955056608
	139945955056608 [label=AccumulateGrad]
	139945955056664 -> 139945955056384
	139946103111256 [label="model.block7.rep.8.bias
 (728)" fillcolor=lightblue]
	139946103111256 -> 139945955056664
	139945955056664 [label=AccumulateGrad]
	139945955056440 -> 139945955054144
	139945955056160 -> 139945955055936
	139946103222344 [label="model.block8.rep.1.conv1.weight
 (728, 1, 3, 3)" fillcolor=lightblue]
	139946103222344 -> 139945955056160
	139945955056160 [label=AccumulateGrad]
	139945955055992 -> 139945955055712
	139946103222504 [label="model.block8.rep.1.pointwise.weight
 (728, 728, 1, 1)" fillcolor=lightblue]
	139946103222504 -> 139945955055992
	139945955055992 [label=AccumulateGrad]
	139945955055768 -> 139945955055544
	139946103222584 [label="model.block8.rep.2.weight
 (728)" fillcolor=lightblue]
	139946103222584 -> 139945955055768
	139945955055768 [label=AccumulateGrad]
	139945955055824 -> 139945955055544
	139946103222664 [label="model.block8.rep.2.bias
 (728)" fillcolor=lightblue]
	139946103222664 -> 139945955055824
	139945955055824 [label=AccumulateGrad]
	139945955055432 -> 139945955055208
	139946103223064 [label="model.block8.rep.4.conv1.weight
 (728, 1, 3, 3)" fillcolor=lightblue]
	139946103223064 -> 139945955055432
	139945955055432 [label=AccumulateGrad]
	139945955055264 -> 139945955054984
	139946103223224 [label="model.block8.rep.4.pointwise.weight
 (728, 728, 1, 1)" fillcolor=lightblue]
	139946103223224 -> 139945955055264
	139945955055264 [label=AccumulateGrad]
	139945955055040 -> 139945955054816
	139946103223304 [label="model.block8.rep.5.weight
 (728)" fillcolor=lightblue]
	139946103223304 -> 139945955055040
	139945955055040 [label=AccumulateGrad]
	139945955055096 -> 139945955054816
	139946103223384 [label="model.block8.rep.5.bias
 (728)" fillcolor=lightblue]
	139946103223384 -> 139945955055096
	139945955055096 [label=AccumulateGrad]
	139945955054704 -> 139945955054480
	139946103223784 [label="model.block8.rep.7.conv1.weight
 (728, 1, 3, 3)" fillcolor=lightblue]
	139946103223784 -> 139945955054704
	139945955054704 [label=AccumulateGrad]
	139945955054536 -> 139945955054256
	139946103223944 [label="model.block8.rep.7.pointwise.weight
 (728, 728, 1, 1)" fillcolor=lightblue]
	139946103223944 -> 139945955054536
	139945955054536 [label=AccumulateGrad]
	139945955054312 -> 139945955054088
	139946103224024 [label="model.block8.rep.8.weight
 (728)" fillcolor=lightblue]
	139946103224024 -> 139945955054312
	139945955054312 [label=AccumulateGrad]
	139945955054368 -> 139945955054088
	139946103224104 [label="model.block8.rep.8.bias
 (728)" fillcolor=lightblue]
	139946103224104 -> 139945955054368
	139945955054368 [label=AccumulateGrad]
	139945955054144 -> 139945955043592
	139945955053864 -> 139945955053640
	139946103224504 [label="model.block9.rep.1.conv1.weight
 (728, 1, 3, 3)" fillcolor=lightblue]
	139946103224504 -> 139945955053864
	139945955053864 [label=AccumulateGrad]
	139945955053696 -> 139945955045160
	139946103224664 [label="model.block9.rep.1.pointwise.weight
 (728, 728, 1, 1)" fillcolor=lightblue]
	139946103224664 -> 139945955053696
	139945955053696 [label=AccumulateGrad]
	139945955045216 -> 139945955044992
	139946103224744 [label="model.block9.rep.2.weight
 (728)" fillcolor=lightblue]
	139946103224744 -> 139945955045216
	139945955045216 [label=AccumulateGrad]
	139945955045272 -> 139945955044992
	139946103224824 [label="model.block9.rep.2.bias
 (728)" fillcolor=lightblue]
	139946103224824 -> 139945955045272
	139945955045272 [label=AccumulateGrad]
	139945955044880 -> 139945955044656
	139946103225224 [label="model.block9.rep.4.conv1.weight
 (728, 1, 3, 3)" fillcolor=lightblue]
	139946103225224 -> 139945955044880
	139945955044880 [label=AccumulateGrad]
	139945955044712 -> 139945955044432
	139946103225384 [label="model.block9.rep.4.pointwise.weight
 (728, 728, 1, 1)" fillcolor=lightblue]
	139946103225384 -> 139945955044712
	139945955044712 [label=AccumulateGrad]
	139945955044488 -> 139945955044264
	139946103225464 [label="model.block9.rep.5.weight
 (728)" fillcolor=lightblue]
	139946103225464 -> 139945955044488
	139945955044488 [label=AccumulateGrad]
	139945955044544 -> 139945955044264
	139946103225544 [label="model.block9.rep.5.bias
 (728)" fillcolor=lightblue]
	139946103225544 -> 139945955044544
	139945955044544 [label=AccumulateGrad]
	139945955044152 -> 139945955043928
	139946103225944 [label="model.block9.rep.7.conv1.weight
 (728, 1, 3, 3)" fillcolor=lightblue]
	139946103225944 -> 139945955044152
	139945955044152 [label=AccumulateGrad]
	139945955043984 -> 139945955043704
	139946103226104 [label="model.block9.rep.7.pointwise.weight
 (728, 728, 1, 1)" fillcolor=lightblue]
	139946103226104 -> 139945955043984
	139945955043984 [label=AccumulateGrad]
	139945955043760 -> 139945955043536
	139946103226184 [label="model.block9.rep.8.weight
 (728)" fillcolor=lightblue]
	139946103226184 -> 139945955043760
	139945955043760 [label=AccumulateGrad]
	139945955043816 -> 139945955043536
	139946103226264 [label="model.block9.rep.8.bias
 (728)" fillcolor=lightblue]
	139946103226264 -> 139945955043816
	139945955043816 [label=AccumulateGrad]
	139945955043592 -> 139945955037136
	139945955043312 -> 139945955043088
	139946103308680 [label="model.block10.rep.1.conv1.weight
 (728, 1, 3, 3)" fillcolor=lightblue]
	139946103308680 -> 139945955043312
	139945955043312 [label=AccumulateGrad]
	139945955043144 -> 139945955042864
	139946103308840 [label="model.block10.rep.1.pointwise.weight
 (728, 728, 1, 1)" fillcolor=lightblue]
	139946103308840 -> 139945955043144
	139945955043144 [label=AccumulateGrad]
	139945955042920 -> 139945955042696
	139946103308920 [label="model.block10.rep.2.weight
 (728)" fillcolor=lightblue]
	139946103308920 -> 139945955042920
	139945955042920 [label=AccumulateGrad]
	139945955042976 -> 139945955042696
	139946103309000 [label="model.block10.rep.2.bias
 (728)" fillcolor=lightblue]
	139946103309000 -> 139945955042976
	139945955042976 [label=AccumulateGrad]
	139945955042584 -> 139945955042360
	139946103309400 [label="model.block10.rep.4.conv1.weight
 (728, 1, 3, 3)" fillcolor=lightblue]
	139946103309400 -> 139945955042584
	139945955042584 [label=AccumulateGrad]
	139945955042416 -> 139945955042136
	139946103309560 [label="model.block10.rep.4.pointwise.weight
 (728, 728, 1, 1)" fillcolor=lightblue]
	139946103309560 -> 139945955042416
	139945955042416 [label=AccumulateGrad]
	139945955042192 -> 139945955041968
	139946103309640 [label="model.block10.rep.5.weight
 (728)" fillcolor=lightblue]
	139946103309640 -> 139945955042192
	139945955042192 [label=AccumulateGrad]
	139945955042248 -> 139945955041968
	139946103309720 [label="model.block10.rep.5.bias
 (728)" fillcolor=lightblue]
	139946103309720 -> 139945955042248
	139945955042248 [label=AccumulateGrad]
	139945955041856 -> 139945955041632
	139946103310120 [label="model.block10.rep.7.conv1.weight
 (728, 1, 3, 3)" fillcolor=lightblue]
	139946103310120 -> 139945955041856
	139945955041856 [label=AccumulateGrad]
	139945955041688 -> 139945955041408
	139946103310280 [label="model.block10.rep.7.pointwise.weight
 (728, 728, 1, 1)" fillcolor=lightblue]
	139946103310280 -> 139945955041688
	139945955041688 [label=AccumulateGrad]
	139945955041464 -> 139945955037080
	139946103310360 [label="model.block10.rep.8.weight
 (728)" fillcolor=lightblue]
	139946103310360 -> 139945955041464
	139945955041464 [label=AccumulateGrad]
	139945955041520 -> 139945955037080
	139946103310440 [label="model.block10.rep.8.bias
 (728)" fillcolor=lightblue]
	139946103310440 -> 139945955041520
	139945955041520 [label=AccumulateGrad]
	139945955037136 -> 139945955034840
	139945955036856 -> 139945955036632
	139946103310840 [label="model.block11.rep.1.conv1.weight
 (728, 1, 3, 3)" fillcolor=lightblue]
	139946103310840 -> 139945955036856
	139945955036856 [label=AccumulateGrad]
	139945955036688 -> 139945955036408
	139946103311000 [label="model.block11.rep.1.pointwise.weight
 (728, 728, 1, 1)" fillcolor=lightblue]
	139946103311000 -> 139945955036688
	139945955036688 [label=AccumulateGrad]
	139945955036464 -> 139945955036240
	139946103311080 [label="model.block11.rep.2.weight
 (728)" fillcolor=lightblue]
	139946103311080 -> 139945955036464
	139945955036464 [label=AccumulateGrad]
	139945955036520 -> 139945955036240
	139946103311160 [label="model.block11.rep.2.bias
 (728)" fillcolor=lightblue]
	139946103311160 -> 139945955036520
	139945955036520 [label=AccumulateGrad]
	139945955036128 -> 139945955035904
	139946103311560 [label="model.block11.rep.4.conv1.weight
 (728, 1, 3, 3)" fillcolor=lightblue]
	139946103311560 -> 139945955036128
	139945955036128 [label=AccumulateGrad]
	139945955035960 -> 139945955035680
	139946103311720 [label="model.block11.rep.4.pointwise.weight
 (728, 728, 1, 1)" fillcolor=lightblue]
	139946103311720 -> 139945955035960
	139945955035960 [label=AccumulateGrad]
	139945955035736 -> 139945955035512
	139946103311800 [label="model.block11.rep.5.weight
 (728)" fillcolor=lightblue]
	139946103311800 -> 139945955035736
	139945955035736 [label=AccumulateGrad]
	139945955035792 -> 139945955035512
	139946103311880 [label="model.block11.rep.5.bias
 (728)" fillcolor=lightblue]
	139946103311880 -> 139945955035792
	139945955035792 [label=AccumulateGrad]
	139945955035400 -> 139945955035176
	139946103312280 [label="model.block11.rep.7.conv1.weight
 (728, 1, 3, 3)" fillcolor=lightblue]
	139946103312280 -> 139945955035400
	139945955035400 [label=AccumulateGrad]
	139945955035232 -> 139945955034952
	139946075316376 [label="model.block11.rep.7.pointwise.weight
 (728, 728, 1, 1)" fillcolor=lightblue]
	139946075316376 -> 139945955035232
	139945955035232 [label=AccumulateGrad]
	139945955035008 -> 139945955034784
	139946075316456 [label="model.block11.rep.8.weight
 (728)" fillcolor=lightblue]
	139946075316456 -> 139945955035008
	139945955035008 [label=AccumulateGrad]
	139945955035064 -> 139945955034784
	139946075316536 [label="model.block11.rep.8.bias
 (728)" fillcolor=lightblue]
	139946075316536 -> 139945955035064
	139945955035064 [label=AccumulateGrad]
	139945955034840 -> 139945955034672
	139945955034560 -> 139945955034336
	139946075317496 [label="model.block12.rep.1.conv1.weight
 (728, 1, 3, 3)" fillcolor=lightblue]
	139946075317496 -> 139945955034560
	139945955034560 [label=AccumulateGrad]
	139945955034392 -> 139945955034112
	139946075317656 [label="model.block12.rep.1.pointwise.weight
 (728, 728, 1, 1)" fillcolor=lightblue]
	139946075317656 -> 139945955034392
	139945955034392 [label=AccumulateGrad]
	139945955034168 -> 139945955034000
	139946075317736 [label="model.block12.rep.2.weight
 (728)" fillcolor=lightblue]
	139946075317736 -> 139945955034168
	139945955034168 [label=AccumulateGrad]
	139945955034224 -> 139945955034000
	139946075317816 [label="model.block12.rep.2.bias
 (728)" fillcolor=lightblue]
	139946075317816 -> 139945955034224
	139945955034224 [label=AccumulateGrad]
	139945955033888 -> 139945955033664
	139946075318216 [label="model.block12.rep.4.conv1.weight
 (728, 1, 3, 3)" fillcolor=lightblue]
	139946075318216 -> 139945955033888
	139945955033888 [label=AccumulateGrad]
	139945955033720 -> 139945955033440
	139946075318376 [label="model.block12.rep.4.pointwise.weight
 (1024, 728, 1, 1)" fillcolor=lightblue]
	139946075318376 -> 139945955033720
	139945955033720 [label=AccumulateGrad]
	139945955033496 -> 139945955033328
	139946075318456 [label="model.block12.rep.5.weight
 (1024)" fillcolor=lightblue]
	139946075318456 -> 139945955033496
	139945955033496 [label=AccumulateGrad]
	139945955033552 -> 139945955033328
	139946075318536 [label="model.block12.rep.5.bias
 (1024)" fillcolor=lightblue]
	139946075318536 -> 139945955033552
	139945955033552 [label=AccumulateGrad]
	139945955033216 -> 139946075459424
	139945955033216 [label=NativeBatchNormBackward0]
	139945955033384 -> 139945955033216
	139945955033384 [label=MkldnnConvolutionBackward0]
	139945955034672 -> 139945955033384
	139945955034056 -> 139945955033384
	139946075316936 [label="model.block12.skip.weight
 (1024, 728, 1, 1)" fillcolor=lightblue]
	139946075316936 -> 139945955034056
	139945955034056 [label=AccumulateGrad]
	139945955033608 -> 139945955033216
	139946075317016 [label="model.block12.skipbn.weight
 (1024)" fillcolor=lightblue]
	139946075317016 -> 139945955033608
	139945955033608 [label=AccumulateGrad]
	139945955033776 -> 139945955033216
	139946075317096 [label="model.block12.skipbn.bias
 (1024)" fillcolor=lightblue]
	139946075317096 -> 139945955033776
	139945955033776 [label=AccumulateGrad]
	139946075459480 -> 139946075459256
	139946075318936 [label="model.conv3.conv1.weight
 (1024, 1, 3, 3)" fillcolor=lightblue]
	139946075318936 -> 139946075459480
	139946075459480 [label=AccumulateGrad]
	139946075459312 -> 139946075459032
	139946075319096 [label="model.conv3.pointwise.weight
 (1536, 1024, 1, 1)" fillcolor=lightblue]
	139946075319096 -> 139946075459312
	139946075459312 [label=AccumulateGrad]
	139946075459088 -> 139946075458920
	139946075319176 [label="model.bn3.weight
 (1536)" fillcolor=lightblue]
	139946075319176 -> 139946075459088
	139946075459088 [label=AccumulateGrad]
	139946075459144 -> 139946075458920
	139946075319256 [label="model.bn3.bias
 (1536)" fillcolor=lightblue]
	139946075319256 -> 139946075459144
	139946075459144 [label=AccumulateGrad]
	139946075458808 -> 139946075458584
	139946075319656 [label="model.conv4.conv1.weight
 (1536, 1, 3, 3)" fillcolor=lightblue]
	139946075319656 -> 139946075458808
	139946075458808 [label=AccumulateGrad]
	139946075458640 -> 139946075458360
	139946075319816 [label="model.conv4.pointwise.weight
 (2048, 1536, 1, 1)" fillcolor=lightblue]
	139946075319816 -> 139946075458640
	139946075458640 [label=AccumulateGrad]
	139946075458416 -> 139946075458248
	139946075319896 [label="model.bn4.weight
 (2048)" fillcolor=lightblue]
	139946075319896 -> 139946075458416
	139946075458416 [label=AccumulateGrad]
	139946075458472 -> 139946075458248
	139946075319976 [label="model.bn4.bias
 (2048)" fillcolor=lightblue]
	139946075319976 -> 139946075458472
	139946075458472 [label=AccumulateGrad]
	139946075457800 -> 139946075457688
	139946075457800 [label=TBackward0]
	139946075457968 -> 139946075457800
	139946075410664 [label="model.last_linear.1.weight
 (2, 2048)" fillcolor=lightblue]
	139946075410664 -> 139946075457968
	139946075457968 [label=AccumulateGrad]
	139946075457408 -> 139946075320136
	139945954992280 [label="
 (1, 2)" fillcolor=darkolivegreen3]
	139946075457688 -> 139945954992280
	139945954992280 -> 139946075320136 [style=dotted]
}
