job begin
Job begin at 2021-11-23 16:19:11.718566
Data = All_c40
Epoch = 20
Weight_decay = 1e-05
Let's use 1 GPUs!
Using dropout 0.5
Epoch 1/20
====================
/public/dengzhijian/miniconda3/envs/ffpp/lib/python3.6/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
iteration    200 train loss: 0.0222 Acc: 0.4375
iteration    400 train loss: 0.0194 Acc: 0.6875
iteration    600 train loss: 0.0215 Acc: 0.5625
iteration    800 train loss: 0.0215 Acc: 0.5938
iteration   1000 train loss: 0.0220 Acc: 0.4062
iteration   1200 train loss: 0.0240 Acc: 0.3125
iteration   1400 train loss: 0.0229 Acc: 0.4688
iteration   1600 train loss: 0.0214 Acc: 0.5000
iteration   1800 train loss: 0.0214 Acc: 0.6250
iteration   2000 train loss: 0.0225 Acc: 0.3750
iteration   2200 train loss: 0.0222 Acc: 0.5312
iteration   2400 train loss: 0.0224 Acc: 0.5312
iteration   2600 train loss: 0.0211 Acc: 0.5625
iteration   2800 train loss: 0.0215 Acc: 0.5312
iteration   3000 train loss: 0.0212 Acc: 0.5000
iteration   3200 train loss: 0.0219 Acc: 0.4688
iteration   3400 train loss: 0.0242 Acc: 0.5000
iteration   3600 train loss: 0.0216 Acc: 0.5312
iteration   3800 train loss: 0.0219 Acc: 0.5000
iteration   4000 train loss: 0.0216 Acc: 0.5312
iteration   4200 train loss: 0.0223 Acc: 0.4375
iteration   4400 train loss: 0.0222 Acc: 0.4375
iteration   4600 train loss: 0.0214 Acc: 0.5625
iteration   4800 train loss: 0.0225 Acc: 0.4375
iteration   5000 train loss: 0.0221 Acc: 0.4375
iteration   5200 train loss: 0.0219 Acc: 0.5312
iteration   5400 train loss: 0.0223 Acc: 0.3750
iteration   5600 train loss: 0.0220 Acc: 0.5625
iteration   5800 train loss: 0.0215 Acc: 0.5312
iteration   6000 train loss: 0.0221 Acc: 0.5000
iteration   6200 train loss: 0.0219 Acc: 0.4375
iteration   6400 train loss: 0.0223 Acc: 0.3750
iteration   6600 train loss: 0.0209 Acc: 0.5000
iteration   6800 train loss: 0.0224 Acc: 0.3750
iteration   7000 train loss: 0.0217 Acc: 0.5312
iteration   7200 train loss: 0.0219 Acc: 0.4688
iteration   7400 train loss: 0.0221 Acc: 0.4375
iteration   7600 train loss: 0.0217 Acc: 0.4688
iteration   7800 train loss: 0.0212 Acc: 0.5625
iteration   8000 train loss: 0.0215 Acc: 0.5000
iteration   8200 train loss: 0.0211 Acc: 0.6562
iteration   8400 train loss: 0.0200 Acc: 0.7812
iteration   8600 train loss: 0.0228 Acc: 0.4688
iteration   8800 train loss: 0.0209 Acc: 0.6562
iteration   9000 train loss: 0.0219 Acc: 0.4688
iteration   9200 train loss: 0.0216 Acc: 0.5625
iteration   9400 train loss: 0.0216 Acc: 0.6250
iteration   9600 train loss: 0.0225 Acc: 0.5000
iteration   9800 train loss: 0.0216 Acc: 0.5312
iteration  10000 train loss: 0.0210 Acc: 0.6562
iteration  10200 train loss: 0.0215 Acc: 0.5312
iteration  10400 train loss: 0.0226 Acc: 0.4375
iteration  10600 train loss: 0.0219 Acc: 0.5312
epoch 1 use 1:15:39.021987
epoch train loss: 0.0217 Acc: 0.5305
epoch val loss: 0.0216 Acc: 0.5359 

Epoch 2/20
====================
iteration  10800 train loss: 0.0223 Acc: 0.3438
iteration  11000 train loss: 0.0212 Acc: 0.5938
iteration  11200 train loss: 0.0217 Acc: 0.5312
iteration  11400 train loss: 0.0219 Acc: 0.4375
iteration  11600 train loss: 0.0218 Acc: 0.5312
iteration  11800 train loss: 0.0232 Acc: 0.4375
iteration  12000 train loss: 0.0212 Acc: 0.5938
iteration  12200 train loss: 0.0212 Acc: 0.6250
iteration  12400 train loss: 0.0220 Acc: 0.5000
iteration  12600 train loss: 0.0214 Acc: 0.5312
iteration  12800 train loss: 0.0219 Acc: 0.4688
iteration  13000 train loss: 0.0210 Acc: 0.6250
iteration  13200 train loss: 0.0224 Acc: 0.4688
iteration  13400 train loss: 0.0215 Acc: 0.5938
iteration  13600 train loss: 0.0206 Acc: 0.6562
iteration  13800 train loss: 0.0218 Acc: 0.4688
iteration  14000 train loss: 0.0218 Acc: 0.4688
iteration  14200 train loss: 0.0221 Acc: 0.4062
iteration  14400 train loss: 0.0211 Acc: 0.6250
iteration  14600 train loss: 0.0215 Acc: 0.5312
iteration  14800 train loss: 0.0220 Acc: 0.4375
iteration  15000 train loss: 0.0211 Acc: 0.6250
iteration  15200 train loss: 0.0212 Acc: 0.5938
iteration  15400 train loss: 0.0217 Acc: 0.5312
iteration  15600 train loss: 0.0219 Acc: 0.5000
iteration  15800 train loss: 0.0214 Acc: 0.5625
iteration  16000 train loss: 0.0216 Acc: 0.5312
iteration  16200 train loss: 0.0215 Acc: 0.5625
iteration  16400 train loss: 0.0217 Acc: 0.5312
iteration  16600 train loss: 0.0214 Acc: 0.5625
iteration  16800 train loss: 0.0221 Acc: 0.4062
iteration  17000 train loss: 0.0213 Acc: 0.5938
iteration  17200 train loss: 0.0207 Acc: 0.7188
iteration  17400 train loss: 0.0219 Acc: 0.4688
iteration  17600 train loss: 0.0216 Acc: 0.5312
iteration  17800 train loss: 0.0214 Acc: 0.5938
iteration  18000 train loss: 0.0217 Acc: 0.5312
iteration  18200 train loss: 0.0216 Acc: 0.5312
iteration  18400 train loss: 0.0218 Acc: 0.4375
iteration  18600 train loss: 0.0224 Acc: 0.4062
iteration  18800 train loss: 0.0216 Acc: 0.5312
iteration  19000 train loss: 0.0222 Acc: 0.4375
iteration  19200 train loss: 0.0214 Acc: 0.5938
iteration  19400 train loss: 0.0211 Acc: 0.6562
iteration  19600 train loss: 0.0213 Acc: 0.5938
iteration  19800 train loss: 0.0214 Acc: 0.5625
iteration  20000 train loss: 0.0225 Acc: 0.3750
iteration  20200 train loss: 0.0217 Acc: 0.5312
iteration  20400 train loss: 0.0212 Acc: 0.6250
iteration  20600 train loss: 0.0210 Acc: 0.6250
iteration  20800 train loss: 0.0217 Acc: 0.5312
iteration  21000 train loss: 0.0217 Acc: 0.5312
iteration  21200 train loss: 0.0216 Acc: 0.5000
epoch 2 use 1:34:16.106605
epoch train loss: 0.0216 Acc: 0.5357
epoch val loss: 0.0216 Acc: 0.5389 

Epoch 3/20
====================
iteration  21400 train loss: 0.0217 Acc: 0.5312
iteration  21600 train loss: 0.0209 Acc: 0.6875
iteration  21800 train loss: 0.0216 Acc: 0.5312
iteration  22000 train loss: 0.0215 Acc: 0.5625
iteration  22200 train loss: 0.0219 Acc: 0.4688
iteration  22400 train loss: 0.0228 Acc: 0.3438
iteration  22600 train loss: 0.0213 Acc: 0.6250
iteration  22800 train loss: 0.0214 Acc: 0.5625
iteration  23000 train loss: 0.0218 Acc: 0.4688
iteration  23200 train loss: 0.0213 Acc: 0.5938
iteration  23400 train loss: 0.0216 Acc: 0.5625
iteration  23600 train loss: 0.0219 Acc: 0.4688
iteration  23800 train loss: 0.0214 Acc: 0.5938
iteration  24000 train loss: 0.0222 Acc: 0.4062
iteration  24200 train loss: 0.0219 Acc: 0.4688
iteration  24400 train loss: 0.0214 Acc: 0.6562
iteration  24600 train loss: 0.0217 Acc: 0.5000
iteration  24800 train loss: 0.0226 Acc: 0.3125
iteration  25000 train loss: 0.0210 Acc: 0.6562
iteration  25200 train loss: 0.0215 Acc: 0.5625
iteration  25400 train loss: 0.0212 Acc: 0.6562
iteration  25600 train loss: 0.0219 Acc: 0.4688
iteration  25800 train loss: 0.0212 Acc: 0.6250
iteration  26000 train loss: 0.0217 Acc: 0.5000
iteration  26200 train loss: 0.0219 Acc: 0.4688
iteration  26400 train loss: 0.0218 Acc: 0.5000
iteration  26600 train loss: 0.0212 Acc: 0.5938
iteration  26800 train loss: 0.0213 Acc: 0.6562
iteration  27000 train loss: 0.0219 Acc: 0.4688
iteration  27200 train loss: 0.0225 Acc: 0.3750
iteration  27400 train loss: 0.0216 Acc: 0.5312
iteration  27600 train loss: 0.0215 Acc: 0.5625
iteration  27800 train loss: 0.0223 Acc: 0.3438
iteration  28000 train loss: 0.0213 Acc: 0.5938
iteration  28200 train loss: 0.0210 Acc: 0.6562
iteration  28400 train loss: 0.0211 Acc: 0.6250
iteration  28600 train loss: 0.0217 Acc: 0.5312
iteration  28800 train loss: 0.0218 Acc: 0.5000
iteration  29000 train loss: 0.0216 Acc: 0.5000
iteration  29200 train loss: 0.0211 Acc: 0.6875
iteration  29400 train loss: 0.0216 Acc: 0.5312
iteration  29600 train loss: 0.0216 Acc: 0.5312
iteration  29800 train loss: 0.0220 Acc: 0.4688
iteration  30000 train loss: 0.0212 Acc: 0.6250
iteration  30200 train loss: 0.0226 Acc: 0.3438
iteration  30400 train loss: 0.0214 Acc: 0.5938
iteration  30600 train loss: 0.0213 Acc: 0.5938
iteration  30800 train loss: 0.0220 Acc: 0.4375
iteration  31000 train loss: 0.0216 Acc: 0.5312
iteration  31200 train loss: 0.0221 Acc: 0.3750
iteration  31400 train loss: 0.0221 Acc: 0.4688
iteration  31600 train loss: 0.0218 Acc: 0.5000
iteration  31800 train loss: 0.0218 Acc: 0.5000
epoch 3 use 1:31:27.913626
epoch train loss: 0.0216 Acc: 0.5373
epoch val loss: 0.0216 Acc: 0.5389 

Epoch 4/20
====================
iteration  32000 train loss: 0.0208 Acc: 0.6875
iteration  32200 train loss: 0.0217 Acc: 0.5312
iteration  32400 train loss: 0.0212 Acc: 0.5938
iteration  32600 train loss: 0.0209 Acc: 0.6875
iteration  32800 train loss: 0.0215 Acc: 0.6250
iteration  33000 train loss: 0.0215 Acc: 0.5938
iteration  33200 train loss: 0.0216 Acc: 0.5000
iteration  33400 train loss: 0.0224 Acc: 0.3750
iteration  33600 train loss: 0.0215 Acc: 0.5625
iteration  33800 train loss: 0.0216 Acc: 0.5312
iteration  34000 train loss: 0.0213 Acc: 0.6250
iteration  34200 train loss: 0.0216 Acc: 0.5312
iteration  34400 train loss: 0.0224 Acc: 0.3438
iteration  34600 train loss: 0.0221 Acc: 0.4375
iteration  34800 train loss: 0.0221 Acc: 0.3750
iteration  35000 train loss: 0.0218 Acc: 0.4688
iteration  35200 train loss: 0.0218 Acc: 0.5000
iteration  35400 train loss: 0.0218 Acc: 0.5312
iteration  35600 train loss: 0.0227 Acc: 0.3750
iteration  35800 train loss: 0.0218 Acc: 0.4688
iteration  36000 train loss: 0.0219 Acc: 0.4688
iteration  36200 train loss: 0.0213 Acc: 0.6562
iteration  36400 train loss: 0.0217 Acc: 0.5312
iteration  36600 train loss: 0.0213 Acc: 0.5625
iteration  36800 train loss: 0.0213 Acc: 0.5938
iteration  37000 train loss: 0.0213 Acc: 0.5938
iteration  37200 train loss: 0.0223 Acc: 0.3750
iteration  37400 train loss: 0.0216 Acc: 0.5312
iteration  37600 train loss: 0.0217 Acc: 0.5000
iteration  37800 train loss: 0.0221 Acc: 0.4062
iteration  38000 train loss: 0.0207 Acc: 0.6250
iteration  38200 train loss: 0.0216 Acc: 0.5625
iteration  38400 train loss: 0.0216 Acc: 0.5625
iteration  38600 train loss: 0.0211 Acc: 0.6562
iteration  38800 train loss: 0.0218 Acc: 0.4688
iteration  39000 train loss: 0.0216 Acc: 0.5000
iteration  39200 train loss: 0.0217 Acc: 0.5312
iteration  39400 train loss: 0.0216 Acc: 0.5312
iteration  39600 train loss: 0.0211 Acc: 0.6250
iteration  39800 train loss: 0.0211 Acc: 0.6250
iteration  40000 train loss: 0.0215 Acc: 0.5625
iteration  40200 train loss: 0.0211 Acc: 0.6562
iteration  40400 train loss: 0.0220 Acc: 0.4375
iteration  40600 train loss: 0.0210 Acc: 0.6250
iteration  40800 train loss: 0.0215 Acc: 0.5625
iteration  41000 train loss: 0.0226 Acc: 0.4062
iteration  41200 train loss: 0.0214 Acc: 0.5938
iteration  41400 train loss: 0.0215 Acc: 0.5625
iteration  41600 train loss: 0.0217 Acc: 0.5000
iteration  41800 train loss: 0.0217 Acc: 0.5312
iteration  42000 train loss: 0.0207 Acc: 0.7188
iteration  42200 train loss: 0.0213 Acc: 0.5625
iteration  42400 train loss: 0.0215 Acc: 0.5312
epoch 4 use 1:33:32.387962
epoch train loss: 0.0216 Acc: 0.5373
epoch val loss: 0.0216 Acc: 0.5389 

Epoch 5/20
====================
iteration  42600 train loss: 0.0218 Acc: 0.4688
iteration  42800 train loss: 0.0223 Acc: 0.3438
iteration  43000 train loss: 0.0216 Acc: 0.5312
iteration  43200 train loss: 0.0214 Acc: 0.5938
iteration  43400 train loss: 0.0225 Acc: 0.4062
iteration  43600 train loss: 0.0216 Acc: 0.5625
iteration  43800 train loss: 0.0212 Acc: 0.5938
iteration  44000 train loss: 0.0221 Acc: 0.4375
iteration  44200 train loss: 0.0208 Acc: 0.6562
iteration  44400 train loss: 0.0215 Acc: 0.5000
iteration  44600 train loss: 0.0214 Acc: 0.5625
iteration  44800 train loss: 0.0216 Acc: 0.5312
iteration  45000 train loss: 0.0205 Acc: 0.7188
iteration  45200 train loss: 0.0213 Acc: 0.5625
iteration  45400 train loss: 0.0212 Acc: 0.5938
iteration  45600 train loss: 0.0217 Acc: 0.5000
iteration  45800 train loss: 0.0216 Acc: 0.5000
iteration  46000 train loss: 0.0211 Acc: 0.5938
iteration  46200 train loss: 0.0217 Acc: 0.5000
iteration  46400 train loss: 0.0215 Acc: 0.5000
iteration  46600 train loss: 0.0215 Acc: 0.5312
iteration  46800 train loss: 0.0212 Acc: 0.6250
iteration  47000 train loss: 0.0216 Acc: 0.5312
iteration  47200 train loss: 0.0215 Acc: 0.6250
iteration  47400 train loss: 0.0215 Acc: 0.5000
iteration  47600 train loss: 0.0214 Acc: 0.5938
iteration  47800 train loss: 0.0211 Acc: 0.6875
iteration  48000 train loss: 0.0218 Acc: 0.5000
iteration  48200 train loss: 0.0219 Acc: 0.5000
iteration  48400 train loss: 0.0216 Acc: 0.5312
iteration  48600 train loss: 0.0211 Acc: 0.6562
iteration  48800 train loss: 0.0219 Acc: 0.4688
iteration  49000 train loss: 0.0210 Acc: 0.6250
iteration  49200 train loss: 0.0214 Acc: 0.5938
iteration  49400 train loss: 0.0218 Acc: 0.4688
iteration  49600 train loss: 0.0215 Acc: 0.5938
iteration  49800 train loss: 0.0213 Acc: 0.5938
iteration  50000 train loss: 0.0219 Acc: 0.4375
iteration  50200 train loss: 0.0214 Acc: 0.5312
iteration  50400 train loss: 0.0216 Acc: 0.5312
iteration  50600 train loss: 0.0213 Acc: 0.5938
iteration  50800 train loss: 0.0217 Acc: 0.5000
iteration  51000 train loss: 0.0218 Acc: 0.5000
iteration  51200 train loss: 0.0209 Acc: 0.6562
iteration  51400 train loss: 0.0215 Acc: 0.5625
iteration  51600 train loss: 0.0211 Acc: 0.6562
iteration  51800 train loss: 0.0216 Acc: 0.5312
iteration  52000 train loss: 0.0219 Acc: 0.5000
iteration  52200 train loss: 0.0214 Acc: 0.5625
iteration  52400 train loss: 0.0216 Acc: 0.5312
iteration  52600 train loss: 0.0220 Acc: 0.4375
iteration  52800 train loss: 0.0217 Acc: 0.5312
iteration  53000 train loss: 0.0210 Acc: 0.6562
epoch 5 use 1:35:31.612245
epoch train loss: 0.0216 Acc: 0.5373
epoch val loss: 0.0216 Acc: 0.5389 

Epoch 6/20
====================
iteration  53200 train loss: 0.0220 Acc: 0.4375
iteration  53400 train loss: 0.0214 Acc: 0.5938
iteration  53600 train loss: 0.0215 Acc: 0.5625
iteration  53800 train loss: 0.0219 Acc: 0.4688
iteration  54000 train loss: 0.0217 Acc: 0.4688
iteration  54200 train loss: 0.0220 Acc: 0.4688
iteration  54400 train loss: 0.0219 Acc: 0.4688
iteration  54600 train loss: 0.0220 Acc: 0.4375
iteration  54800 train loss: 0.0221 Acc: 0.4375
iteration  55000 train loss: 0.0216 Acc: 0.5312
iteration  55200 train loss: 0.0211 Acc: 0.6250
iteration  55400 train loss: 0.0217 Acc: 0.5312
iteration  55600 train loss: 0.0216 Acc: 0.5312
iteration  55800 train loss: 0.0214 Acc: 0.5938
iteration  56000 train loss: 0.0218 Acc: 0.5000
iteration  56200 train loss: 0.0221 Acc: 0.4062
iteration  56400 train loss: 0.0211 Acc: 0.6562
iteration  56600 train loss: 0.0213 Acc: 0.6250
iteration  56800 train loss: 0.0215 Acc: 0.5312
iteration  57000 train loss: 0.0222 Acc: 0.4062
iteration  57200 train loss: 0.0211 Acc: 0.6250
iteration  57400 train loss: 0.0214 Acc: 0.5625
iteration  57600 train loss: 0.0213 Acc: 0.5625
iteration  57800 train loss: 0.0207 Acc: 0.6562
iteration  58000 train loss: 0.0214 Acc: 0.5625
iteration  58200 train loss: 0.0221 Acc: 0.4062
iteration  58400 train loss: 0.0223 Acc: 0.4062
iteration  58600 train loss: 0.0222 Acc: 0.4062
iteration  58800 train loss: 0.0212 Acc: 0.6250
iteration  59000 train loss: 0.0210 Acc: 0.6875
iteration  59200 train loss: 0.0211 Acc: 0.6875
iteration  59400 train loss: 0.0215 Acc: 0.5312
iteration  59600 train loss: 0.0218 Acc: 0.5000
iteration  59800 train loss: 0.0216 Acc: 0.5312
iteration  60000 train loss: 0.0216 Acc: 0.5625
iteration  60200 train loss: 0.0222 Acc: 0.4375
iteration  60400 train loss: 0.0210 Acc: 0.6562
iteration  60600 train loss: 0.0206 Acc: 0.7188
iteration  60800 train loss: 0.0213 Acc: 0.5625
iteration  61000 train loss: 0.0213 Acc: 0.6250
iteration  61200 train loss: 0.0211 Acc: 0.6250
iteration  61400 train loss: 0.0214 Acc: 0.5625
iteration  61600 train loss: 0.0215 Acc: 0.5312
iteration  61800 train loss: 0.0215 Acc: 0.5625
iteration  62000 train loss: 0.0216 Acc: 0.5625
iteration  62200 train loss: 0.0218 Acc: 0.5000
iteration  62400 train loss: 0.0216 Acc: 0.5312
iteration  62600 train loss: 0.0214 Acc: 0.6250
iteration  62800 train loss: 0.0220 Acc: 0.4375
iteration  63000 train loss: 0.0215 Acc: 0.5625
iteration  63200 train loss: 0.0218 Acc: 0.5312
iteration  63400 train loss: 0.0215 Acc: 0.5625
iteration  63600 train loss: 0.0216 Acc: 0.5625
epoch 6 use 1:28:34.797519
epoch train loss: 0.0216 Acc: 0.5374
epoch val loss: 0.0216 Acc: 0.5389 

Epoch 7/20
====================
iteration  63800 train loss: 0.0223 Acc: 0.4062
iteration  64000 train loss: 0.0218 Acc: 0.5000
iteration  64200 train loss: 0.0209 Acc: 0.6875
iteration  64400 train loss: 0.0220 Acc: 0.4062
iteration  64600 train loss: 0.0215 Acc: 0.5625
iteration  64800 train loss: 0.0213 Acc: 0.5938
iteration  65000 train loss: 0.0218 Acc: 0.5000
iteration  65200 train loss: 0.0213 Acc: 0.5938
iteration  65400 train loss: 0.0221 Acc: 0.4688
iteration  65600 train loss: 0.0222 Acc: 0.4062
iteration  65800 train loss: 0.0216 Acc: 0.5312
iteration  66000 train loss: 0.0214 Acc: 0.5625
iteration  66200 train loss: 0.0214 Acc: 0.5625
iteration  66400 train loss: 0.0215 Acc: 0.5625
iteration  66600 train loss: 0.0217 Acc: 0.5312
iteration  66800 train loss: 0.0217 Acc: 0.5000
iteration  67000 train loss: 0.0221 Acc: 0.3750
iteration  67200 train loss: 0.0217 Acc: 0.5000
iteration  67400 train loss: 0.0215 Acc: 0.5312
iteration  67600 train loss: 0.0216 Acc: 0.5312
iteration  67800 train loss: 0.0209 Acc: 0.6562
iteration  68000 train loss: 0.0212 Acc: 0.5938
iteration  68200 train loss: 0.0226 Acc: 0.3438
iteration  68400 train loss: 0.0228 Acc: 0.2500
iteration  68600 train loss: 0.0218 Acc: 0.5000
iteration  68800 train loss: 0.0212 Acc: 0.6250
iteration  69000 train loss: 0.0216 Acc: 0.5312
iteration  69200 train loss: 0.0211 Acc: 0.6562
iteration  69400 train loss: 0.0213 Acc: 0.5938
iteration  69600 train loss: 0.0217 Acc: 0.5312
iteration  69800 train loss: 0.0219 Acc: 0.4375
iteration  70000 train loss: 0.0216 Acc: 0.5000
iteration  70200 train loss: 0.0215 Acc: 0.5625
iteration  70400 train loss: 0.0221 Acc: 0.4375
iteration  70600 train loss: 0.0214 Acc: 0.5625
iteration  70800 train loss: 0.0216 Acc: 0.5312
iteration  71000 train loss: 0.0221 Acc: 0.4375
iteration  71200 train loss: 0.0214 Acc: 0.5938
iteration  71400 train loss: 0.0223 Acc: 0.4062
iteration  71600 train loss: 0.0210 Acc: 0.6875
iteration  71800 train loss: 0.0208 Acc: 0.6875
iteration  72000 train loss: 0.0206 Acc: 0.7188
iteration  72200 train loss: 0.0220 Acc: 0.4688
iteration  72400 train loss: 0.0208 Acc: 0.6875
iteration  72600 train loss: 0.0220 Acc: 0.4688
iteration  72800 train loss: 0.0215 Acc: 0.5625
iteration  73000 train loss: 0.0222 Acc: 0.4375
iteration  73200 train loss: 0.0214 Acc: 0.5625
iteration  73400 train loss: 0.0212 Acc: 0.6250
iteration  73600 train loss: 0.0223 Acc: 0.4062
iteration  73800 train loss: 0.0211 Acc: 0.6250
iteration  74000 train loss: 0.0218 Acc: 0.5000
iteration  74200 train loss: 0.0207 Acc: 0.7188
iteration  74400 train loss: 0.0212 Acc: 0.6250
epoch 7 use 1:27:40.160035
epoch train loss: 0.0216 Acc: 0.5374
epoch val loss: 0.0216 Acc: 0.5389 

Epoch 8/20
====================
iteration  74600 train loss: 0.0214 Acc: 0.5625
iteration  74800 train loss: 0.0211 Acc: 0.6250
iteration  75000 train loss: 0.0215 Acc: 0.5312
iteration  75200 train loss: 0.0218 Acc: 0.4688
iteration  75400 train loss: 0.0219 Acc: 0.4688
iteration  75600 train loss: 0.0219 Acc: 0.4688
iteration  75800 train loss: 0.0215 Acc: 0.5625
iteration  76000 train loss: 0.0215 Acc: 0.5625
iteration  76200 train loss: 0.0214 Acc: 0.5625
iteration  76400 train loss: 0.0213 Acc: 0.6250
iteration  76600 train loss: 0.0220 Acc: 0.4688
iteration  76800 train loss: 0.0217 Acc: 0.5625
iteration  77000 train loss: 0.0215 Acc: 0.5625
iteration  77200 train loss: 0.0208 Acc: 0.6875
iteration  77400 train loss: 0.0211 Acc: 0.6250
iteration  77600 train loss: 0.0217 Acc: 0.5312
iteration  77800 train loss: 0.0217 Acc: 0.5000
iteration  78000 train loss: 0.0207 Acc: 0.6875
iteration  78200 train loss: 0.0218 Acc: 0.4688
iteration  78400 train loss: 0.0209 Acc: 0.6562
iteration  78600 train loss: 0.0214 Acc: 0.5625
iteration  78800 train loss: 0.0211 Acc: 0.6562
iteration  79000 train loss: 0.0219 Acc: 0.4688
iteration  79200 train loss: 0.0206 Acc: 0.7188
iteration  79400 train loss: 0.0216 Acc: 0.5312
iteration  79600 train loss: 0.0212 Acc: 0.6250
iteration  79800 train loss: 0.0216 Acc: 0.5312
iteration  80000 train loss: 0.0225 Acc: 0.3750
iteration  80200 train loss: 0.0217 Acc: 0.5000
iteration  80400 train loss: 0.0224 Acc: 0.3438
iteration  80600 train loss: 0.0216 Acc: 0.5312
iteration  80800 train loss: 0.0218 Acc: 0.5000
iteration  81000 train loss: 0.0216 Acc: 0.5312
iteration  81200 train loss: 0.0211 Acc: 0.6250
iteration  81400 train loss: 0.0217 Acc: 0.5000
iteration  81600 train loss: 0.0221 Acc: 0.4375
iteration  81800 train loss: 0.0214 Acc: 0.6250
iteration  82000 train loss: 0.0209 Acc: 0.6875
iteration  82200 train loss: 0.0213 Acc: 0.5938
iteration  82400 train loss: 0.0212 Acc: 0.6250
iteration  82600 train loss: 0.0209 Acc: 0.6875
iteration  82800 train loss: 0.0220 Acc: 0.4688
iteration  83000 train loss: 0.0204 Acc: 0.7812
iteration  83200 train loss: 0.0220 Acc: 0.4688
iteration  83400 train loss: 0.0219 Acc: 0.4688
iteration  83600 train loss: 0.0216 Acc: 0.5312
iteration  83800 train loss: 0.0216 Acc: 0.5312
iteration  84000 train loss: 0.0217 Acc: 0.5312
iteration  84200 train loss: 0.0218 Acc: 0.5000
iteration  84400 train loss: 0.0221 Acc: 0.4375
iteration  84600 train loss: 0.0215 Acc: 0.5625
iteration  84800 train loss: 0.0219 Acc: 0.4688
iteration  85000 train loss: 0.0211 Acc: 0.6562
epoch 8 use 1:32:00.144636
epoch train loss: 0.0216 Acc: 0.5374
epoch val loss: 0.0216 Acc: 0.5389 

Epoch 9/20
====================
iteration  85200 train loss: 0.0213 Acc: 0.5938
iteration  85400 train loss: 0.0216 Acc: 0.5000
iteration  85600 train loss: 0.0214 Acc: 0.5625
iteration  85800 train loss: 0.0216 Acc: 0.5312
iteration  86000 train loss: 0.0220 Acc: 0.4688
iteration  86200 train loss: 0.0215 Acc: 0.5625
iteration  86400 train loss: 0.0212 Acc: 0.5938
iteration  86600 train loss: 0.0211 Acc: 0.6250
iteration  86800 train loss: 0.0219 Acc: 0.4688
iteration  87000 train loss: 0.0217 Acc: 0.5000
iteration  87200 train loss: 0.0223 Acc: 0.4062
iteration  87400 train loss: 0.0217 Acc: 0.5312
iteration  87600 train loss: 0.0215 Acc: 0.5312
iteration  87800 train loss: 0.0221 Acc: 0.4375
iteration  88000 train loss: 0.0212 Acc: 0.6250
iteration  88200 train loss: 0.0221 Acc: 0.4375
iteration  88400 train loss: 0.0216 Acc: 0.5625
iteration  88600 train loss: 0.0222 Acc: 0.3750
iteration  88800 train loss: 0.0218 Acc: 0.4688
iteration  89000 train loss: 0.0216 Acc: 0.5312
iteration  89200 train loss: 0.0216 Acc: 0.5625
iteration  89400 train loss: 0.0214 Acc: 0.5625
iteration  89600 train loss: 0.0219 Acc: 0.4688
iteration  89800 train loss: 0.0209 Acc: 0.6562
iteration  90000 train loss: 0.0223 Acc: 0.3750
iteration  90200 train loss: 0.0214 Acc: 0.5625
iteration  90400 train loss: 0.0214 Acc: 0.5938
iteration  90600 train loss: 0.0215 Acc: 0.5312
iteration  90800 train loss: 0.0214 Acc: 0.5625
iteration  91000 train loss: 0.0218 Acc: 0.5000
iteration  91200 train loss: 0.0221 Acc: 0.4062
iteration  91400 train loss: 0.0223 Acc: 0.3125
iteration  91600 train loss: 0.0222 Acc: 0.4062
iteration  91800 train loss: 0.0215 Acc: 0.5625
iteration  92000 train loss: 0.0212 Acc: 0.5938
iteration  92200 train loss: 0.0214 Acc: 0.5938
iteration  92400 train loss: 0.0218 Acc: 0.5000
iteration  92600 train loss: 0.0213 Acc: 0.5938
iteration  92800 train loss: 0.0218 Acc: 0.5000
iteration  93000 train loss: 0.0218 Acc: 0.4688
iteration  93200 train loss: 0.0210 Acc: 0.6875
iteration  93400 train loss: 0.0217 Acc: 0.5312
iteration  93600 train loss: 0.0213 Acc: 0.6562
iteration  93800 train loss: 0.0210 Acc: 0.6875
iteration  94000 train loss: 0.0214 Acc: 0.5625
iteration  94200 train loss: 0.0211 Acc: 0.6250
iteration  94400 train loss: 0.0209 Acc: 0.7500
iteration  94600 train loss: 0.0215 Acc: 0.5312
iteration  94800 train loss: 0.0214 Acc: 0.5938
iteration  95000 train loss: 0.0209 Acc: 0.6875
iteration  95200 train loss: 0.0224 Acc: 0.4062
iteration  95400 train loss: 0.0218 Acc: 0.5312
iteration  95600 train loss: 0.0216 Acc: 0.5312
epoch 9 use 1:33:09.439426
epoch train loss: 0.0216 Acc: 0.5374
epoch val loss: 0.0216 Acc: 0.5389 

Epoch 10/20
====================
iteration  95800 train loss: 0.0215 Acc: 0.5312
iteration  96000 train loss: 0.0220 Acc: 0.4375
iteration  96200 train loss: 0.0207 Acc: 0.6875
iteration  96400 train loss: 0.0211 Acc: 0.6562
iteration  96600 train loss: 0.0215 Acc: 0.5625
iteration  96800 train loss: 0.0214 Acc: 0.5938
iteration  97000 train loss: 0.0215 Acc: 0.5625
iteration  97200 train loss: 0.0218 Acc: 0.5000
iteration  97400 train loss: 0.0215 Acc: 0.5312
iteration  97600 train loss: 0.0221 Acc: 0.4375
iteration  97800 train loss: 0.0219 Acc: 0.4688
iteration  98000 train loss: 0.0216 Acc: 0.5312
iteration  98200 train loss: 0.0207 Acc: 0.7188
iteration  98400 train loss: 0.0215 Acc: 0.5625
iteration  98600 train loss: 0.0219 Acc: 0.4688
iteration  98800 train loss: 0.0216 Acc: 0.5312
iteration  99000 train loss: 0.0216 Acc: 0.5312
iteration  99200 train loss: 0.0209 Acc: 0.6875
iteration  99400 train loss: 0.0217 Acc: 0.5312
iteration  99600 train loss: 0.0227 Acc: 0.3438
iteration  99800 train loss: 0.0219 Acc: 0.4688
iteration 100000 train loss: 0.0209 Acc: 0.6562
iteration 100200 train loss: 0.0208 Acc: 0.7188
iteration 100400 train loss: 0.0216 Acc: 0.5312
iteration 100600 train loss: 0.0212 Acc: 0.6250
iteration 100800 train loss: 0.0216 Acc: 0.5312
iteration 101000 train loss: 0.0211 Acc: 0.6250
iteration 101200 train loss: 0.0211 Acc: 0.6562
iteration 101400 train loss: 0.0220 Acc: 0.4688
iteration 101600 train loss: 0.0210 Acc: 0.5938
iteration 101800 train loss: 0.0213 Acc: 0.5938
iteration 102000 train loss: 0.0223 Acc: 0.4062
iteration 102200 train loss: 0.0215 Acc: 0.5625
iteration 102400 train loss: 0.0210 Acc: 0.6875
iteration 102600 train loss: 0.0217 Acc: 0.5312
iteration 102800 train loss: 0.0216 Acc: 0.5625
iteration 103000 train loss: 0.0213 Acc: 0.6562
iteration 103200 train loss: 0.0212 Acc: 0.6250
iteration 103400 train loss: 0.0215 Acc: 0.5625
iteration 103600 train loss: 0.0219 Acc: 0.4375
iteration 103800 train loss: 0.0219 Acc: 0.4688
iteration 104000 train loss: 0.0217 Acc: 0.5000
iteration 104200 train loss: 0.0219 Acc: 0.5000
iteration 104400 train loss: 0.0212 Acc: 0.5938
iteration 104600 train loss: 0.0222 Acc: 0.4062
iteration 104800 train loss: 0.0217 Acc: 0.4688
iteration 105000 train loss: 0.0215 Acc: 0.5625
iteration 105200 train loss: 0.0218 Acc: 0.5000
iteration 105400 train loss: 0.0219 Acc: 0.5000
iteration 105600 train loss: 0.0221 Acc: 0.4375
iteration 105800 train loss: 0.0218 Acc: 0.5000
iteration 106000 train loss: 0.0216 Acc: 0.5312
iteration 106200 train loss: 0.0213 Acc: 0.5938
epoch 10 use 1:37:45.989755
epoch train loss: 0.0216 Acc: 0.5374
epoch val loss: 0.0216 Acc: 0.5389 

Epoch 11/20
====================
iteration 106400 train loss: 0.0215 Acc: 0.5625
iteration 106600 train loss: 0.0215 Acc: 0.5312
iteration 106800 train loss: 0.0215 Acc: 0.5625
iteration 107000 train loss: 0.0212 Acc: 0.6250
iteration 107200 train loss: 0.0218 Acc: 0.5000
iteration 107400 train loss: 0.0212 Acc: 0.6250
iteration 107600 train loss: 0.0215 Acc: 0.5625
iteration 107800 train loss: 0.0215 Acc: 0.5625
iteration 108000 train loss: 0.0216 Acc: 0.5312
iteration 108200 train loss: 0.0216 Acc: 0.5312
iteration 108400 train loss: 0.0210 Acc: 0.6875
iteration 108600 train loss: 0.0218 Acc: 0.5000
iteration 108800 train loss: 0.0213 Acc: 0.5938
iteration 109000 train loss: 0.0215 Acc: 0.5625
iteration 109200 train loss: 0.0219 Acc: 0.4688
iteration 109400 train loss: 0.0217 Acc: 0.5000
iteration 109600 train loss: 0.0213 Acc: 0.5938
iteration 109800 train loss: 0.0212 Acc: 0.6250
iteration 110000 train loss: 0.0213 Acc: 0.5938
iteration 110200 train loss: 0.0209 Acc: 0.6562
iteration 110400 train loss: 0.0218 Acc: 0.5000
iteration 110600 train loss: 0.0207 Acc: 0.7188
iteration 110800 train loss: 0.0215 Acc: 0.5625
iteration 111000 train loss: 0.0218 Acc: 0.5000
iteration 111200 train loss: 0.0217 Acc: 0.5312
iteration 111400 train loss: 0.0215 Acc: 0.5312
iteration 111600 train loss: 0.0217 Acc: 0.5000
iteration 111800 train loss: 0.0211 Acc: 0.6875
iteration 112000 train loss: 0.0216 Acc: 0.5312
iteration 112200 train loss: 0.0220 Acc: 0.4375
iteration 112400 train loss: 0.0218 Acc: 0.5000
iteration 112600 train loss: 0.0209 Acc: 0.6875
iteration 112800 train loss: 0.0211 Acc: 0.6250
iteration 113000 train loss: 0.0211 Acc: 0.6562
iteration 113200 train loss: 0.0221 Acc: 0.4375
iteration 113400 train loss: 0.0210 Acc: 0.6562
iteration 113600 train loss: 0.0209 Acc: 0.6875
iteration 113800 train loss: 0.0216 Acc: 0.5000
iteration 114000 train loss: 0.0206 Acc: 0.6875
iteration 114200 train loss: 0.0214 Acc: 0.5938
iteration 114400 train loss: 0.0209 Acc: 0.6875
iteration 114600 train loss: 0.0216 Acc: 0.5312
iteration 114800 train loss: 0.0216 Acc: 0.5312
iteration 115000 train loss: 0.0211 Acc: 0.6250
iteration 115200 train loss: 0.0210 Acc: 0.6562
iteration 115400 train loss: 0.0210 Acc: 0.6562
iteration 115600 train loss: 0.0210 Acc: 0.6562
iteration 115800 train loss: 0.0219 Acc: 0.4375
iteration 116000 train loss: 0.0217 Acc: 0.5000
iteration 116200 train loss: 0.0211 Acc: 0.6875
iteration 116400 train loss: 0.0214 Acc: 0.5625
iteration 116600 train loss: 0.0216 Acc: 0.5312
iteration 116800 train loss: 0.0216 Acc: 0.5312
epoch 11 use 1:27:26.207337
epoch train loss: 0.0216 Acc: 0.5374
epoch val loss: 0.0216 Acc: 0.5389 

Epoch 12/20
====================
iteration 117000 train loss: 0.0214 Acc: 0.5625
iteration 117200 train loss: 0.0215 Acc: 0.5625
iteration 117400 train loss: 0.0211 Acc: 0.6250
iteration 117600 train loss: 0.0211 Acc: 0.6250
iteration 117800 train loss: 0.0209 Acc: 0.6875
iteration 118000 train loss: 0.0218 Acc: 0.5000
iteration 118200 train loss: 0.0216 Acc: 0.5312
iteration 118400 train loss: 0.0217 Acc: 0.5000
iteration 118600 train loss: 0.0213 Acc: 0.5938
iteration 118800 train loss: 0.0215 Acc: 0.5312
iteration 119000 train loss: 0.0219 Acc: 0.4688
iteration 119200 train loss: 0.0219 Acc: 0.4688
iteration 119400 train loss: 0.0209 Acc: 0.6562
iteration 119600 train loss: 0.0217 Acc: 0.5312
iteration 119800 train loss: 0.0210 Acc: 0.6562
iteration 120000 train loss: 0.0210 Acc: 0.6562
iteration 120200 train loss: 0.0213 Acc: 0.5938
iteration 120400 train loss: 0.0216 Acc: 0.5312
iteration 120600 train loss: 0.0216 Acc: 0.5312
iteration 120800 train loss: 0.0211 Acc: 0.6562
iteration 121000 train loss: 0.0219 Acc: 0.4688
iteration 121200 train loss: 0.0216 Acc: 0.5312
iteration 121400 train loss: 0.0212 Acc: 0.5938
iteration 121600 train loss: 0.0212 Acc: 0.5938
iteration 121800 train loss: 0.0212 Acc: 0.6250
iteration 122000 train loss: 0.0215 Acc: 0.5625
iteration 122200 train loss: 0.0218 Acc: 0.5000
iteration 122400 train loss: 0.0222 Acc: 0.4375
iteration 122600 train loss: 0.0216 Acc: 0.5312
iteration 122800 train loss: 0.0220 Acc: 0.4375
iteration 123000 train loss: 0.0219 Acc: 0.4375
iteration 123200 train loss: 0.0222 Acc: 0.4375
iteration 123400 train loss: 0.0215 Acc: 0.5625
iteration 123600 train loss: 0.0216 Acc: 0.5312
iteration 123800 train loss: 0.0213 Acc: 0.6250
iteration 124000 train loss: 0.0212 Acc: 0.6250
iteration 124200 train loss: 0.0218 Acc: 0.5000
iteration 124400 train loss: 0.0216 Acc: 0.5312
iteration 124600 train loss: 0.0221 Acc: 0.4375
iteration 124800 train loss: 0.0220 Acc: 0.4375
iteration 125000 train loss: 0.0209 Acc: 0.6875
iteration 125200 train loss: 0.0212 Acc: 0.6250
iteration 125400 train loss: 0.0210 Acc: 0.6875
iteration 125600 train loss: 0.0216 Acc: 0.5312
iteration 125800 train loss: 0.0217 Acc: 0.5000
iteration 126000 train loss: 0.0213 Acc: 0.5938
iteration 126200 train loss: 0.0216 Acc: 0.5312
iteration 126400 train loss: 0.0208 Acc: 0.6875
iteration 126600 train loss: 0.0215 Acc: 0.5625
iteration 126800 train loss: 0.0215 Acc: 0.5625
iteration 127000 train loss: 0.0209 Acc: 0.6875
iteration 127200 train loss: 0.0221 Acc: 0.4062
iteration 127400 train loss: 0.0211 Acc: 0.6562
epoch 12 use 1:27:19.817537
epoch train loss: 0.0216 Acc: 0.5374
epoch val loss: 0.0216 Acc: 0.5389 

Epoch 13/20
====================
iteration 127600 train loss: 0.0217 Acc: 0.5312
iteration 127800 train loss: 0.0209 Acc: 0.6875
iteration 128000 train loss: 0.0212 Acc: 0.5938
iteration 128200 train loss: 0.0211 Acc: 0.6250
iteration 128400 train loss: 0.0214 Acc: 0.5625
iteration 128600 train loss: 0.0216 Acc: 0.5312
iteration 128800 train loss: 0.0218 Acc: 0.5000
iteration 129000 train loss: 0.0211 Acc: 0.6250
iteration 129200 train loss: 0.0218 Acc: 0.4688
iteration 129400 train loss: 0.0213 Acc: 0.5938
iteration 129600 train loss: 0.0214 Acc: 0.5625
iteration 129800 train loss: 0.0216 Acc: 0.5312
iteration 130000 train loss: 0.0215 Acc: 0.5625
iteration 130200 train loss: 0.0222 Acc: 0.4375
iteration 130400 train loss: 0.0209 Acc: 0.6875
iteration 130600 train loss: 0.0218 Acc: 0.5000
iteration 130800 train loss: 0.0216 Acc: 0.5312
iteration 131000 train loss: 0.0213 Acc: 0.5938
iteration 131200 train loss: 0.0218 Acc: 0.5000
iteration 131400 train loss: 0.0210 Acc: 0.6562
iteration 131600 train loss: 0.0216 Acc: 0.5312
iteration 131800 train loss: 0.0219 Acc: 0.4688
iteration 132000 train loss: 0.0218 Acc: 0.4688
iteration 132200 train loss: 0.0213 Acc: 0.6250
iteration 132400 train loss: 0.0221 Acc: 0.4688
iteration 132600 train loss: 0.0218 Acc: 0.5000
iteration 132800 train loss: 0.0217 Acc: 0.5000
iteration 133000 train loss: 0.0219 Acc: 0.4688
iteration 133200 train loss: 0.0215 Acc: 0.5625
iteration 133400 train loss: 0.0214 Acc: 0.5625
iteration 133600 train loss: 0.0221 Acc: 0.4375
iteration 133800 train loss: 0.0214 Acc: 0.5625
iteration 134000 train loss: 0.0214 Acc: 0.5625
iteration 134200 train loss: 0.0221 Acc: 0.4375
iteration 134400 train loss: 0.0214 Acc: 0.5625
iteration 134600 train loss: 0.0213 Acc: 0.5938
iteration 134800 train loss: 0.0219 Acc: 0.4375
iteration 135000 train loss: 0.0211 Acc: 0.6562
iteration 135200 train loss: 0.0214 Acc: 0.5938
iteration 135400 train loss: 0.0215 Acc: 0.5625
iteration 135600 train loss: 0.0215 Acc: 0.5625
iteration 135800 train loss: 0.0214 Acc: 0.5625
iteration 136000 train loss: 0.0215 Acc: 0.5625
iteration 136200 train loss: 0.0220 Acc: 0.4688
iteration 136400 train loss: 0.0221 Acc: 0.4375
iteration 136600 train loss: 0.0212 Acc: 0.6250
iteration 136800 train loss: 0.0214 Acc: 0.5625
iteration 137000 train loss: 0.0222 Acc: 0.4062
iteration 137200 train loss: 0.0218 Acc: 0.4688
iteration 137400 train loss: 0.0206 Acc: 0.7500
iteration 137600 train loss: 0.0208 Acc: 0.7188
iteration 137800 train loss: 0.0216 Acc: 0.5312
iteration 138000 train loss: 0.0224 Acc: 0.3438
epoch 13 use 1:26:29.485411
epoch train loss: 0.0216 Acc: 0.5374
epoch val loss: 0.0216 Acc: 0.5389 

Epoch 14/20
====================
iteration 138200 train loss: 0.0219 Acc: 0.4688
iteration 138400 train loss: 0.0213 Acc: 0.5938
iteration 138600 train loss: 0.0214 Acc: 0.5625
iteration 138800 train loss: 0.0213 Acc: 0.5938
iteration 139000 train loss: 0.0216 Acc: 0.5312
iteration 139200 train loss: 0.0217 Acc: 0.5000
iteration 139400 train loss: 0.0209 Acc: 0.6875
iteration 139600 train loss: 0.0210 Acc: 0.6875
iteration 139800 train loss: 0.0217 Acc: 0.5000
iteration 140000 train loss: 0.0213 Acc: 0.5938
iteration 140200 train loss: 0.0226 Acc: 0.3438
iteration 140400 train loss: 0.0207 Acc: 0.7188
iteration 140600 train loss: 0.0217 Acc: 0.5312
iteration 140800 train loss: 0.0211 Acc: 0.6250
iteration 141000 train loss: 0.0221 Acc: 0.4375
iteration 141200 train loss: 0.0214 Acc: 0.5625
iteration 141400 train loss: 0.0215 Acc: 0.5625
iteration 141600 train loss: 0.0218 Acc: 0.4688
iteration 141800 train loss: 0.0213 Acc: 0.6250
iteration 142000 train loss: 0.0217 Acc: 0.5000
iteration 142200 train loss: 0.0207 Acc: 0.7188
iteration 142400 train loss: 0.0212 Acc: 0.5938
iteration 142600 train loss: 0.0216 Acc: 0.5312
iteration 142800 train loss: 0.0226 Acc: 0.3125
iteration 143000 train loss: 0.0219 Acc: 0.4688
iteration 143200 train loss: 0.0218 Acc: 0.5000
iteration 143400 train loss: 0.0216 Acc: 0.5312
iteration 143600 train loss: 0.0217 Acc: 0.5000
iteration 143800 train loss: 0.0213 Acc: 0.5938
iteration 144000 train loss: 0.0206 Acc: 0.7500
iteration 144200 train loss: 0.0215 Acc: 0.5625
iteration 144400 train loss: 0.0225 Acc: 0.3438
iteration 144600 train loss: 0.0218 Acc: 0.5000
iteration 144800 train loss: 0.0219 Acc: 0.4688
iteration 145000 train loss: 0.0213 Acc: 0.5938
iteration 145200 train loss: 0.0209 Acc: 0.6562
iteration 145400 train loss: 0.0215 Acc: 0.5312
iteration 145600 train loss: 0.0216 Acc: 0.5312
iteration 145800 train loss: 0.0210 Acc: 0.6562
iteration 146000 train loss: 0.0218 Acc: 0.5000
iteration 146200 train loss: 0.0210 Acc: 0.6562
iteration 146400 train loss: 0.0212 Acc: 0.6250
iteration 146600 train loss: 0.0221 Acc: 0.4375
iteration 146800 train loss: 0.0219 Acc: 0.4688
iteration 147000 train loss: 0.0222 Acc: 0.4062
iteration 147200 train loss: 0.0203 Acc: 0.7812
iteration 147400 train loss: 0.0214 Acc: 0.5625
iteration 147600 train loss: 0.0213 Acc: 0.5938
iteration 147800 train loss: 0.0217 Acc: 0.5312
iteration 148000 train loss: 0.0219 Acc: 0.4688
iteration 148200 train loss: 0.0214 Acc: 0.5938
iteration 148400 train loss: 0.0216 Acc: 0.5312
iteration 148600 train loss: 0.0220 Acc: 0.4375
iteration 148800 train loss: 0.0217 Acc: 0.5000
epoch 14 use 1:36:26.537896
epoch train loss: 0.0216 Acc: 0.5374
epoch val loss: 0.0216 Acc: 0.5389 

Epoch 15/20
====================
iteration 149000 train loss: 0.0221 Acc: 0.4375
iteration 149200 train loss: 0.0217 Acc: 0.5312
iteration 149400 train loss: 0.0215 Acc: 0.5625
iteration 149600 train loss: 0.0216 Acc: 0.5312
iteration 149800 train loss: 0.0213 Acc: 0.5938
iteration 150000 train loss: 0.0216 Acc: 0.5312
iteration 150200 train loss: 0.0216 Acc: 0.5312
iteration 150400 train loss: 0.0214 Acc: 0.5625
iteration 150600 train loss: 0.0218 Acc: 0.5000
iteration 150800 train loss: 0.0216 Acc: 0.5312
iteration 151000 train loss: 0.0224 Acc: 0.4062
iteration 151200 train loss: 0.0209 Acc: 0.6875
iteration 151400 train loss: 0.0214 Acc: 0.5625
iteration 151600 train loss: 0.0216 Acc: 0.5312
iteration 151800 train loss: 0.0219 Acc: 0.4688
iteration 152000 train loss: 0.0206 Acc: 0.7188
iteration 152200 train loss: 0.0217 Acc: 0.5312
iteration 152400 train loss: 0.0213 Acc: 0.5938
iteration 152600 train loss: 0.0220 Acc: 0.4688
iteration 152800 train loss: 0.0217 Acc: 0.5312
iteration 153000 train loss: 0.0215 Acc: 0.5625
iteration 153200 train loss: 0.0213 Acc: 0.5938
iteration 153400 train loss: 0.0217 Acc: 0.5000
iteration 153600 train loss: 0.0216 Acc: 0.5312
iteration 153800 train loss: 0.0216 Acc: 0.5312
iteration 154000 train loss: 0.0214 Acc: 0.5625
iteration 154200 train loss: 0.0216 Acc: 0.5312
iteration 154400 train loss: 0.0215 Acc: 0.5625
iteration 154600 train loss: 0.0214 Acc: 0.5625
iteration 154800 train loss: 0.0218 Acc: 0.5000
iteration 155000 train loss: 0.0215 Acc: 0.5312
iteration 155200 train loss: 0.0204 Acc: 0.8125
iteration 155400 train loss: 0.0221 Acc: 0.4062
iteration 155600 train loss: 0.0218 Acc: 0.5000
iteration 155800 train loss: 0.0217 Acc: 0.5000
iteration 156000 train loss: 0.0216 Acc: 0.5312
iteration 156200 train loss: 0.0222 Acc: 0.4062
iteration 156400 train loss: 0.0219 Acc: 0.4688
iteration 156600 train loss: 0.0216 Acc: 0.5312
iteration 156800 train loss: 0.0227 Acc: 0.3125
iteration 157000 train loss: 0.0218 Acc: 0.4688
iteration 157200 train loss: 0.0213 Acc: 0.5938
iteration 157400 train loss: 0.0218 Acc: 0.5000
iteration 157600 train loss: 0.0216 Acc: 0.5312
iteration 157800 train loss: 0.0221 Acc: 0.4375
iteration 158000 train loss: 0.0214 Acc: 0.5625
iteration 158200 train loss: 0.0207 Acc: 0.7188
iteration 158400 train loss: 0.0208 Acc: 0.6875
iteration 158600 train loss: 0.0214 Acc: 0.5625
iteration 158800 train loss: 0.0223 Acc: 0.3750
iteration 159000 train loss: 0.0210 Acc: 0.6875
iteration 159200 train loss: 0.0219 Acc: 0.4688
iteration 159400 train loss: 0.0217 Acc: 0.5000
epoch 15 use 1:26:24.007733
epoch train loss: 0.0216 Acc: 0.5374
epoch val loss: 0.0216 Acc: 0.5389 

Epoch 16/20
====================
iteration 159600 train loss: 0.0218 Acc: 0.4688
iteration 159800 train loss: 0.0216 Acc: 0.5312
iteration 160000 train loss: 0.0217 Acc: 0.5312
iteration 160200 train loss: 0.0219 Acc: 0.4688
iteration 160400 train loss: 0.0216 Acc: 0.5312
iteration 160600 train loss: 0.0216 Acc: 0.5312
iteration 160800 train loss: 0.0216 Acc: 0.5312
iteration 161000 train loss: 0.0219 Acc: 0.4688
iteration 161200 train loss: 0.0220 Acc: 0.4375
iteration 161400 train loss: 0.0217 Acc: 0.5000
iteration 161600 train loss: 0.0210 Acc: 0.6250
iteration 161800 train loss: 0.0209 Acc: 0.6562
iteration 162000 train loss: 0.0224 Acc: 0.3750
iteration 162200 train loss: 0.0222 Acc: 0.3750
iteration 162400 train loss: 0.0211 Acc: 0.6562
iteration 162600 train loss: 0.0222 Acc: 0.3750
iteration 162800 train loss: 0.0215 Acc: 0.5625
iteration 163000 train loss: 0.0211 Acc: 0.6562
iteration 163200 train loss: 0.0214 Acc: 0.5625
iteration 163400 train loss: 0.0213 Acc: 0.5938
iteration 163600 train loss: 0.0215 Acc: 0.5625
iteration 163800 train loss: 0.0210 Acc: 0.6562
iteration 164000 train loss: 0.0216 Acc: 0.5312
iteration 164200 train loss: 0.0216 Acc: 0.5312
iteration 164400 train loss: 0.0220 Acc: 0.4688
iteration 164600 train loss: 0.0219 Acc: 0.4688
iteration 164800 train loss: 0.0216 Acc: 0.5312
iteration 165000 train loss: 0.0216 Acc: 0.5312
iteration 165200 train loss: 0.0217 Acc: 0.5000
iteration 165400 train loss: 0.0212 Acc: 0.6250
iteration 165600 train loss: 0.0216 Acc: 0.5312
iteration 165800 train loss: 0.0215 Acc: 0.5625
iteration 166000 train loss: 0.0216 Acc: 0.5312
iteration 166200 train loss: 0.0213 Acc: 0.5938
iteration 166400 train loss: 0.0214 Acc: 0.5625
iteration 166600 train loss: 0.0214 Acc: 0.5625
iteration 166800 train loss: 0.0213 Acc: 0.5938
iteration 167000 train loss: 0.0216 Acc: 0.5312
iteration 167200 train loss: 0.0216 Acc: 0.5312
iteration 167400 train loss: 0.0213 Acc: 0.5938
iteration 167600 train loss: 0.0210 Acc: 0.6562
iteration 167800 train loss: 0.0213 Acc: 0.5938
iteration 168000 train loss: 0.0213 Acc: 0.5938
iteration 168200 train loss: 0.0212 Acc: 0.6250
iteration 168400 train loss: 0.0219 Acc: 0.4688
iteration 168600 train loss: 0.0216 Acc: 0.5312
iteration 168800 train loss: 0.0213 Acc: 0.5938
iteration 169000 train loss: 0.0220 Acc: 0.4375
iteration 169200 train loss: 0.0220 Acc: 0.4375
iteration 169400 train loss: 0.0214 Acc: 0.5625
iteration 169600 train loss: 0.0213 Acc: 0.5938
iteration 169800 train loss: 0.0217 Acc: 0.5312
iteration 170000 train loss: 0.0218 Acc: 0.5000
epoch 16 use 1:25:49.327173
epoch train loss: 0.0216 Acc: 0.5374
epoch val loss: 0.0216 Acc: 0.5389 

Epoch 17/20
====================
iteration 170200 train loss: 0.0219 Acc: 0.4688
iteration 170400 train loss: 0.0218 Acc: 0.5000
iteration 170600 train loss: 0.0213 Acc: 0.5938
iteration 170800 train loss: 0.0213 Acc: 0.5938
iteration 171000 train loss: 0.0212 Acc: 0.6250
iteration 171200 train loss: 0.0223 Acc: 0.3750
iteration 171400 train loss: 0.0214 Acc: 0.5625
iteration 171600 train loss: 0.0213 Acc: 0.5938
iteration 171800 train loss: 0.0214 Acc: 0.5625
iteration 172000 train loss: 0.0211 Acc: 0.6250
iteration 172200 train loss: 0.0216 Acc: 0.5312
iteration 172400 train loss: 0.0217 Acc: 0.5000
iteration 172600 train loss: 0.0222 Acc: 0.3750
iteration 172800 train loss: 0.0216 Acc: 0.5312
iteration 173000 train loss: 0.0219 Acc: 0.4688
iteration 173200 train loss: 0.0220 Acc: 0.4375
iteration 173400 train loss: 0.0214 Acc: 0.5625
iteration 173600 train loss: 0.0211 Acc: 0.6250
iteration 173800 train loss: 0.0213 Acc: 0.5938
iteration 174000 train loss: 0.0213 Acc: 0.5938
iteration 174200 train loss: 0.0213 Acc: 0.5938
iteration 174400 train loss: 0.0217 Acc: 0.5000
iteration 174600 train loss: 0.0213 Acc: 0.5938
iteration 174800 train loss: 0.0216 Acc: 0.5312
iteration 175000 train loss: 0.0220 Acc: 0.4375
iteration 175200 train loss: 0.0212 Acc: 0.6250
iteration 175400 train loss: 0.0212 Acc: 0.6250
iteration 175600 train loss: 0.0217 Acc: 0.5312
iteration 175800 train loss: 0.0216 Acc: 0.5312
iteration 176000 train loss: 0.0214 Acc: 0.5625
iteration 176200 train loss: 0.0224 Acc: 0.3438
iteration 176400 train loss: 0.0215 Acc: 0.5625
iteration 176600 train loss: 0.0219 Acc: 0.4688
iteration 176800 train loss: 0.0218 Acc: 0.5000
iteration 177000 train loss: 0.0212 Acc: 0.6250
iteration 177200 train loss: 0.0217 Acc: 0.5000
iteration 177400 train loss: 0.0217 Acc: 0.5000
iteration 177600 train loss: 0.0218 Acc: 0.5000
iteration 177800 train loss: 0.0220 Acc: 0.4375
iteration 178000 train loss: 0.0214 Acc: 0.5625
iteration 178200 train loss: 0.0219 Acc: 0.4688
iteration 178400 train loss: 0.0213 Acc: 0.5938
iteration 178600 train loss: 0.0216 Acc: 0.5312
iteration 178800 train loss: 0.0220 Acc: 0.4375
iteration 179000 train loss: 0.0218 Acc: 0.5000
iteration 179200 train loss: 0.0216 Acc: 0.5312
iteration 179400 train loss: 0.0218 Acc: 0.5000
iteration 179600 train loss: 0.0210 Acc: 0.6562
iteration 179800 train loss: 0.0219 Acc: 0.4688
iteration 180000 train loss: 0.0217 Acc: 0.5000
iteration 180200 train loss: 0.0220 Acc: 0.4688
iteration 180400 train loss: 0.0221 Acc: 0.4375
iteration 180600 train loss: 0.0217 Acc: 0.5312
epoch 17 use 1:26:22.206466
epoch train loss: 0.0216 Acc: 0.5374
epoch val loss: 0.0216 Acc: 0.5389 

Epoch 18/20
====================
iteration 180800 train loss: 0.0211 Acc: 0.6562
iteration 181000 train loss: 0.0214 Acc: 0.5625
iteration 181200 train loss: 0.0213 Acc: 0.5938
iteration 181400 train loss: 0.0212 Acc: 0.6250
iteration 181600 train loss: 0.0216 Acc: 0.5312
iteration 181800 train loss: 0.0212 Acc: 0.6250
iteration 182000 train loss: 0.0219 Acc: 0.4688
iteration 182200 train loss: 0.0213 Acc: 0.5938
iteration 182400 train loss: 0.0217 Acc: 0.5000
iteration 182600 train loss: 0.0212 Acc: 0.6250
iteration 182800 train loss: 0.0221 Acc: 0.4062
iteration 183000 train loss: 0.0217 Acc: 0.5000
iteration 183200 train loss: 0.0219 Acc: 0.4688
iteration 183400 train loss: 0.0216 Acc: 0.5312
iteration 183600 train loss: 0.0219 Acc: 0.4688
iteration 183800 train loss: 0.0212 Acc: 0.6250
iteration 184000 train loss: 0.0214 Acc: 0.5625
iteration 184200 train loss: 0.0220 Acc: 0.4375
iteration 184400 train loss: 0.0214 Acc: 0.5938
iteration 184600 train loss: 0.0217 Acc: 0.5000
iteration 184800 train loss: 0.0215 Acc: 0.5625
iteration 185000 train loss: 0.0218 Acc: 0.5000
iteration 185200 train loss: 0.0216 Acc: 0.5312
iteration 185400 train loss: 0.0213 Acc: 0.5938
iteration 185600 train loss: 0.0215 Acc: 0.5625
iteration 185800 train loss: 0.0212 Acc: 0.6250
iteration 186000 train loss: 0.0210 Acc: 0.6562
iteration 186200 train loss: 0.0220 Acc: 0.4375
iteration 186400 train loss: 0.0215 Acc: 0.5625
iteration 186600 train loss: 0.0217 Acc: 0.5000
iteration 186800 train loss: 0.0219 Acc: 0.4375
iteration 187000 train loss: 0.0217 Acc: 0.5000
iteration 187200 train loss: 0.0218 Acc: 0.5000
iteration 187400 train loss: 0.0216 Acc: 0.5312
iteration 187600 train loss: 0.0223 Acc: 0.4062
iteration 187800 train loss: 0.0216 Acc: 0.5312
iteration 188000 train loss: 0.0212 Acc: 0.6250
iteration 188200 train loss: 0.0222 Acc: 0.4062
iteration 188400 train loss: 0.0216 Acc: 0.5312
iteration 188600 train loss: 0.0214 Acc: 0.5625
iteration 188800 train loss: 0.0211 Acc: 0.6250
iteration 189000 train loss: 0.0213 Acc: 0.5938
iteration 189200 train loss: 0.0213 Acc: 0.5938
iteration 189400 train loss: 0.0219 Acc: 0.4688
iteration 189600 train loss: 0.0218 Acc: 0.5000
iteration 189800 train loss: 0.0219 Acc: 0.4688
iteration 190000 train loss: 0.0217 Acc: 0.5312
iteration 190200 train loss: 0.0217 Acc: 0.5000
iteration 190400 train loss: 0.0208 Acc: 0.7188
iteration 190600 train loss: 0.0214 Acc: 0.5625
iteration 190800 train loss: 0.0219 Acc: 0.4688
iteration 191000 train loss: 0.0211 Acc: 0.6250
iteration 191200 train loss: 0.0215 Acc: 0.5625
epoch 18 use 1:27:29.796087
epoch train loss: 0.0216 Acc: 0.5374
epoch val loss: 0.0216 Acc: 0.5389 

Epoch 19/20
====================
iteration 191400 train loss: 0.0216 Acc: 0.5312
iteration 191600 train loss: 0.0208 Acc: 0.6875
iteration 191800 train loss: 0.0220 Acc: 0.4375
iteration 192000 train loss: 0.0219 Acc: 0.4688
iteration 192200 train loss: 0.0218 Acc: 0.4688
iteration 192400 train loss: 0.0218 Acc: 0.5000
iteration 192600 train loss: 0.0215 Acc: 0.5625
iteration 192800 train loss: 0.0213 Acc: 0.5938
iteration 193000 train loss: 0.0216 Acc: 0.5312
iteration 193200 train loss: 0.0218 Acc: 0.5000
iteration 193400 train loss: 0.0216 Acc: 0.5312
iteration 193600 train loss: 0.0212 Acc: 0.6250
iteration 193800 train loss: 0.0221 Acc: 0.4375
iteration 194000 train loss: 0.0219 Acc: 0.4688
iteration 194200 train loss: 0.0216 Acc: 0.5312
iteration 194400 train loss: 0.0225 Acc: 0.3750
iteration 194600 train loss: 0.0226 Acc: 0.3438
iteration 194800 train loss: 0.0223 Acc: 0.3750
iteration 195000 train loss: 0.0220 Acc: 0.4375
iteration 195200 train loss: 0.0214 Acc: 0.5625
iteration 195400 train loss: 0.0221 Acc: 0.4062
iteration 195600 train loss: 0.0208 Acc: 0.7188
iteration 195800 train loss: 0.0222 Acc: 0.4062
iteration 196000 train loss: 0.0208 Acc: 0.6562
iteration 196200 train loss: 0.0216 Acc: 0.5312
iteration 196400 train loss: 0.0206 Acc: 0.7500
iteration 196600 train loss: 0.0218 Acc: 0.5000
iteration 196800 train loss: 0.0210 Acc: 0.6562
iteration 197000 train loss: 0.0217 Acc: 0.5000
iteration 197200 train loss: 0.0220 Acc: 0.4688
iteration 197400 train loss: 0.0214 Acc: 0.5625
iteration 197600 train loss: 0.0215 Acc: 0.5625
iteration 197800 train loss: 0.0220 Acc: 0.4375
iteration 198000 train loss: 0.0215 Acc: 0.5625
iteration 198200 train loss: 0.0215 Acc: 0.5625
iteration 198400 train loss: 0.0212 Acc: 0.6250
iteration 198600 train loss: 0.0217 Acc: 0.5000
iteration 198800 train loss: 0.0216 Acc: 0.5312
iteration 199000 train loss: 0.0213 Acc: 0.5938
iteration 199200 train loss: 0.0217 Acc: 0.5000
iteration 199400 train loss: 0.0212 Acc: 0.6250
iteration 199600 train loss: 0.0223 Acc: 0.4062
iteration 199800 train loss: 0.0215 Acc: 0.5625
iteration 200000 train loss: 0.0219 Acc: 0.4688
iteration 200200 train loss: 0.0217 Acc: 0.5000
iteration 200400 train loss: 0.0216 Acc: 0.5312
iteration 200600 train loss: 0.0218 Acc: 0.5000
iteration 200800 train loss: 0.0216 Acc: 0.5312
iteration 201000 train loss: 0.0213 Acc: 0.5938
iteration 201200 train loss: 0.0214 Acc: 0.5625
iteration 201400 train loss: 0.0222 Acc: 0.4375
iteration 201600 train loss: 0.0221 Acc: 0.4375
iteration 201800 train loss: 0.0216 Acc: 0.5312
epoch 19 use 1:28:03.266256
epoch train loss: 0.0216 Acc: 0.5374
epoch val loss: 0.0216 Acc: 0.5389 

Epoch 20/20
====================
iteration 202000 train loss: 0.0210 Acc: 0.6562
iteration 202200 train loss: 0.0219 Acc: 0.4688
iteration 202400 train loss: 0.0220 Acc: 0.4688
iteration 202600 train loss: 0.0211 Acc: 0.6250
iteration 202800 train loss: 0.0209 Acc: 0.6562
iteration 203000 train loss: 0.0225 Acc: 0.3438
iteration 203200 train loss: 0.0219 Acc: 0.4688
iteration 203400 train loss: 0.0216 Acc: 0.5312
iteration 203600 train loss: 0.0213 Acc: 0.5938
iteration 203800 train loss: 0.0216 Acc: 0.5312
iteration 204000 train loss: 0.0224 Acc: 0.3750
iteration 204200 train loss: 0.0216 Acc: 0.5312
iteration 204400 train loss: 0.0221 Acc: 0.4375
iteration 204600 train loss: 0.0220 Acc: 0.4375
iteration 204800 train loss: 0.0220 Acc: 0.4375
iteration 205000 train loss: 0.0224 Acc: 0.3750
iteration 205200 train loss: 0.0218 Acc: 0.5000
iteration 205400 train loss: 0.0218 Acc: 0.4688
iteration 205600 train loss: 0.0214 Acc: 0.5938
iteration 205800 train loss: 0.0219 Acc: 0.4375
iteration 206000 train loss: 0.0215 Acc: 0.5625
iteration 206200 train loss: 0.0212 Acc: 0.6250
iteration 206400 train loss: 0.0222 Acc: 0.4062
iteration 206600 train loss: 0.0205 Acc: 0.7188
iteration 206800 train loss: 0.0207 Acc: 0.6875
iteration 207000 train loss: 0.0219 Acc: 0.4688
iteration 207200 train loss: 0.0218 Acc: 0.5000
iteration 207400 train loss: 0.0217 Acc: 0.5000
iteration 207600 train loss: 0.0218 Acc: 0.5000
iteration 207800 train loss: 0.0210 Acc: 0.6875
iteration 208000 train loss: 0.0216 Acc: 0.5312
iteration 208200 train loss: 0.0216 Acc: 0.5312
iteration 208400 train loss: 0.0212 Acc: 0.6250
iteration 208600 train loss: 0.0209 Acc: 0.6875
iteration 208800 train loss: 0.0214 Acc: 0.5625
iteration 209000 train loss: 0.0216 Acc: 0.5312
iteration 209200 train loss: 0.0214 Acc: 0.5625
iteration 209400 train loss: 0.0209 Acc: 0.6875
iteration 209600 train loss: 0.0215 Acc: 0.5625
iteration 209800 train loss: 0.0223 Acc: 0.4062
iteration 210000 train loss: 0.0215 Acc: 0.5625
iteration 210200 train loss: 0.0216 Acc: 0.5312
iteration 210400 train loss: 0.0217 Acc: 0.5000
iteration 210600 train loss: 0.0212 Acc: 0.6250
iteration 210800 train loss: 0.0212 Acc: 0.6250
iteration 211000 train loss: 0.0221 Acc: 0.4375
iteration 211200 train loss: 0.0215 Acc: 0.5625
iteration 211400 train loss: 0.0225 Acc: 0.3125
iteration 211600 train loss: 0.0218 Acc: 0.4688
iteration 211800 train loss: 0.0214 Acc: 0.5625
iteration 212000 train loss: 0.0213 Acc: 0.5938
iteration 212200 train loss: 0.0222 Acc: 0.4062
iteration 212400 train loss: 0.0211 Acc: 0.6562
iteration 212600 train loss: 0.0214 Acc: 0.1250
epoch 20 use 1:30:39.546076
epoch train loss: 0.0216 Acc: 0.5374
epoch val loss: 0.0216 Acc: 0.5389 

Best val Acc: 0.5389 

train+test.py:147: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  logits = nn.functional.softmax(outputs)  # 预测结果的概率形式
Test iteration 400.0000 Acc: 0.4062
Test iteration 800.0000 Acc: 0.5312
Test iteration 1200.0000 Acc: 0.5000
Test iteration 1600.0000 Acc: 0.4688
Test Acc: 0.5317 Preds AUC: 0.5000 Prods AUC: 0.5000
job end
